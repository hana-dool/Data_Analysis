{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T09:25:37.526835Z",
     "start_time": "2020-08-02T09:25:35.250127Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import make_regression\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics # 모델평가시 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T09:25:37.605512Z",
     "start_time": "2020-08-02T09:25:37.527764Z"
    }
   },
   "outputs": [],
   "source": [
    "# dataset 형성하기\n",
    "X, y = make_regression(n_samples=2000, # sample 의 수는 2000개\n",
    "                       n_features=20, # x 변수는 20개\n",
    "                       n_informative=4, # 그중 y 변수와 관련되는 변수는 4개  \n",
    "                       noise = 3       # nosie \n",
    "                      ,effective_rank=15 #  x 변수중 서로 독립인 수 (5개는 서로 관련)\n",
    "                      ,tail_strength=0.3 # 관련된 변수의 관련성\n",
    "                      ,random_state=0) # random state 고정\n",
    "X = pd.DataFrame(X)\n",
    "X[[1,4,6,10,13]]=X[[1,4,6,10,13]]*-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T09:25:37.637397Z",
     "start_time": "2020-08-02T09:25:37.607478Z"
    }
   },
   "outputs": [],
   "source": [
    "# dataset train/test set 으로 나누기\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.7989583 ,  2.60992309,  3.15534149, ..., -0.88908075,\n",
       "       -5.57811736,  3.9804761 ])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 세우기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T09:25:40.053254Z",
     "start_time": "2020-08-02T09:25:39.966332Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T09:25:40.663642Z",
     "start_time": "2020-08-02T09:25:40.641508Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE : 8.611762902052247\n",
      "R squared : 0.20108198497901186\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "y_pred = model.predict(X_test)\n",
    "print (\"MSE :\", metrics.mean_squared_error(y_test,y_pred))\n",
    "print(\"R squared :\", metrics.r2_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polynomial regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "변수가 적다면, 데이터 분석시 부정확 할 수 있다. 그래서 polynomial 로 변수의 갯수를 늘려서 예측도를 높혀보자"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다항회귀는, 데이터를 돌리기 전, x1 x2 -> x1^2 , x1x2, x2^2 처럼 데이터를 바꾸어야 한다.를 해주어야한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T09:25:56.408589Z",
     "start_time": "2020-08-02T09:25:56.387953Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly = PolynomialFeatures()  \n",
    "# degree : 몇 차수까진 늘릴지 결정\n",
    "#        : (default)=2\n",
    "# interaction_only : only 자기 자신의 거듭제곱만 넣을지 말지. (ex x1 x2 -> x1^2 , ^2)\n",
    "#                  : (default)=False (interaction 항 넣기) (EX x1 x2 -> x1^2 , x1x2, x2^2)\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_test_poly = poly.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 세우기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T09:25:57.344304Z",
     "start_time": "2020-08-02T09:25:57.294405Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train_poly, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T09:25:59.685585Z",
     "start_time": "2020-08-02T09:25:59.664616Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE : 10.588639961853904\n",
      "R squared : 0.01768600502455997\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "y_pred = model.predict(X_test_poly)\n",
    "print (\"MSE :\", metrics.mean_squared_error(y_test,y_pred))\n",
    "print(\"R squared :\", metrics.r2_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$w = \\text{arg}\\min_w \\left( \\sum_{i=1}^N e_i^2 + \\lambda \\sum_{j=1}^M w_j^2 \\right) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 세우기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T09:26:03.951055Z",
     "start_time": "2020-08-02T09:26:03.291571Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "para_range = np.logspace(-3, 3, num=50) # 10^-3 ~ 10^3 \n",
    "model = RidgeCV(alphas = para_range , cv=5)\n",
    "# cross validaaion 을 5 fold cross validation 으로 지정 , \n",
    "# para_range 의 범위만큼 ,cv 를 해서 최적의 alpha 를 구하겠다는 의미\n",
    "# RidgeCV = cv 와 ridge 를 동시에 합친 model 이다.\n",
    "model.fit(X_train, y_train) ;\n",
    "# X_train, Y_train 으로 ridgecv 를 fitting 해야 비로소 의미가 생긴다. 위는 setting 작업임.\n",
    "#ridgecv.fit 은 alpha 를 위에서 구한 최적의 값을 써서 ridge regression 을 하겠다는 의미이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T09:26:03.966012Z",
     "start_time": "2020-08-02T09:26:03.953048Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE : 8.606003653527091\n",
      "R_squared : 0.20161627365510082\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "predicted = model.predict(X_test) \n",
    "# 우리가 fitting 한 coefficient 로 X_test 를 이용해 Y_test 를 predict\n",
    "#ridgecv.alpha_ # Estimated regularization parametor (최적값)\n",
    "#ridgecv.coef_ # fitting 한 coff 값들\n",
    "\n",
    "print (\"MSE :\", metrics.mean_squared_error(y_test, predicted))\n",
    "print('R_squared :',model.score(X_test, y_test)) # C-V 로 찾은 최적의 ridge 로 계산한 R^2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ElasticNet Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[모델 원리]**\n",
    "- $w = \\text{arg}\\min_w \\left( \\sum_{i=1}^N e_i^2 + \\lambda_1 \\sum_{j=1}^M | w_j | + \\lambda_2 \\sum_{j=1}^M w_j^2 \\right)$ 로 w 를 정하는 regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Hyperparameter]** \n",
    "- sklearn 에서는 $0.5 \\times \\text{RSS}/N + \\text{alpha} \\times \\big( 0.5 \\times (1-\\text{L1_wt})\\sum w_i^2 + \\text{L1_wt} \\sum |w_i| \\big)$ 을 최소화 한다.(사실상 위랑 똑같다.)\n",
    "- l1_ratio : float, default=0.5\n",
    "     - For l1_ratio = 0 the penalty is an L2 penalty. For l1_ratio = 1 it is an L1 penalty. For 0 < l1_ratio < 1, the penalty is a combination of L1 and L2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T10:27:45.206307Z",
     "start_time": "2020-08-02T10:27:45.202317Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.linear_model import ElasticNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 세우기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T10:27:46.170184Z",
     "start_time": "2020-08-02T10:27:45.693415Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0009717603376703314\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "ElasticCV = ElasticNetCV(l1_ratio =[.1, .5, .7, .9, .95, .99,1], cv=5, random_state=0)\n",
    "# l1 Note that a good choice of list of values for l1_ratio is often to put more values close to 1 (i.e. Lasso) and less close to 0 (i.e. Ridge), as in  [.1, .5, .7, .9, .95, .99, 1] \n",
    "\n",
    "ElasticCV.fit(X_train, y_train)\n",
    "print(ElasticCV.alpha_) # alpha 값\n",
    "print(ElasticCV.l1_ratio_) #l1 ratio 1 이면 사실상 lasso 이다... 1 이 나오면 그냥 lasso 로 하라는 의미"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T10:27:47.113942Z",
     "start_time": "2020-08-02T10:27:47.107397Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE : 8.607510464307282\n",
      "R_squared : 0.20161627365510082\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "predicted = ElasticCV.predict(X_test) \n",
    "# 우리가 fitting 한 coefficient 로 X_test 를 이용해 Y_test 를 predict\n",
    "#ridgecv.alpha_ # Estimated regularization parametor (최적값)\n",
    "#ridgecv.coef_ # fitting 한 coff 값들\n",
    "\n",
    "print (\"MSE :\", metrics.mean_squared_error(y_test, predicted))\n",
    "print('R_squared :',model.score(X_test, y_test)) # C-V 로 찾은 최적의 ridge 로 계산한 R^2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 변수 중요도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T10:27:52.392414Z",
     "start_time": "2020-08-02T10:27:52.193433Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Coefficients in the Model')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "coef = pd.Series(ElasticCV.coef_, index = X_train.columns).sort_values()\n",
    "imp_coef = pd.concat([coef.head(5), coef.tail(5)])\n",
    "imp_coef.plot(kind = \"barh\")\n",
    "plt.title(\"Coefficients in the Model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lasso regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$w = \\text{arg}\\min_w \\left( \\sum_{i=1}^N e_i^2 + \\lambda \\sum_{j=1}^M | w_j | \\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 세우기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import Lasso\n",
    "alphas = np.logspace(-3, 3, num=50) # 10^-3 ~ 10^3 \n",
    "lassocv = LassoCV(alphas = alphas, cv=5)\n",
    "# 위 ridge 때와 동일\n",
    "lassocv.fit(X_train, y_train) ;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE : 8.607540368924692\n",
      "R_squared : 0.20147371171638206\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "predicted = lassocv.predict(X_test) \n",
    "# 우리가 fitting 한 coefficient 로 X_test 를 이용해 Y_test 를 predict\n",
    "#lassocv.alpha_ # Estimated regularization parametor (최적값)\n",
    "#lassocv.coef_ # fitting 한 coff 값들\n",
    "\n",
    "print (\"MSE :\", metrics.mean_squared_error(y_test, predicted))\n",
    "print('R_squared :',lassocv.score(X_test, y_test)) # C-V 로 찾은 최적의 ridge 로 계산한 R^2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 변수 중요도"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "상위 6개의 관려있는 계수들을 보여준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Coefficients in the Model')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAEICAYAAABGaK+TAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy86wFpkAAAACXBIWXMAAAsTAAALEwEAmpwYAAAUMElEQVR4nO3df5xldX3f8dcbEJEfCuyC5fdqQqmWyko3CMEiP8QgIppWHoWowWrF9oEVjNWAWKMm5mHSxGqi1VhBNJpNokCC+CNsSAzVKnZBwCWLoAKCC+wSRFGqYfHTP+7Z7GWYmTtz752Z+11fz8fjPu6955455z27M+858z33zDdVhSSpPdstdQBJ0nAscElqlAUuSY2ywCWpURa4JDXKApekRlngGkmSQ5J8LcmDSV6X5AlJPp3k+0k+meSlSa6cw3benOTDi5F5lgwHJvlhku3HtL23Jfn4OLa1UJLcnuS5c1hvRZJKssNi5NLcWOA/I5L8SpK1XUHdneRzSZ49hk2/CfhCVe1WVX8AvAR4MrCsqk6rqk9U1fMGbaSqfruq/uOoYUYpmqr6TlXtWlWPDLHfY5PcNd+Pm8f2L+4+r1OnLH9Pt/wVC7VvTS4L/GdAkl8D3gP8Nr1yPRD4n8CLxrD5g4Cbpjy/pao2j2HberRbgDO3POl+SJ0GfGvJEmlJWeDbuCRPAt4BnF1Vl1bVj6rq4ar6dFW9sVvn8d2R3Ibu9p4kj+/bxilJrk/yQJL/k+QZ3fK/AY4D3tcd2a8G3gr8++75q5K8IskX+7b1L5OsSXJ/knuTvLlb/qjhhiRHdvt6IMkNSY7te+0LSX4zyZe6oZsrkyzvXr66u3+gy3BUkp9P8nfdsM59Sf5shn+rRx29D9hP/8ftAnwO2Lfb5w+T7Nu9vGOSj3Uff1OSVX0ft2+SS5JsSnJbktcN+O/8NHB0kj265ycBNwL39G1zuyRvSXJHko3dvp/U9/rLu9f+IckFUz6P7ZKcl+Rb3et/nmTPAZm0hCzwbd9RwE7AZbOscwFwJLASOAw4AngLQJLDgYuA1wDLgD8CLk/y+Ko6HvjfwGu7oYcz6B3l/1n3/ML+nSTZDfhr4PPAvsDPA1dNDZNkP+AzwG8BewL/FbgkyV59q/0K8B+AvYEdu3UAjunud+8yfBn4TeBKYA9gf+APZ/m3mGqm/fyTqvoR8HxgQ7fPXatqQ/fyqcCfArsDlwPv6z7H7egV8g3AfsAJwLlJfmmWLD/utnF69/xXgY9NWecV3e044KnArn37fDrwAeDl9P79l9H799jidcCLged0r38PeP8sebTELPBt3zLgvgFDGi8F3lFVG6tqE/B2et/kAK8G/qiqrqmqR6rqo8BP6BX+fJ0C3FNVv19VP66qB6vqmmnWexnw2ar6bFX9tKrWAGuBk/vW+UhV3VJV/w/4c3o/fGbyML2hnX27/X5xlnWnms9+pvPF7vN4BPhjej8gAX4B2Kuq3lFV/1hV3wb+F1vLeSYfA361O6p+DvAXU15/KfDuqvp2Vf0QOB84vfut4iXAFVV1dVX9BPhvwE/7PvY1wAVVdVf3+tuAl3jicnJZ4Nu+fwCWD/gm3Be4o+/5Hd0y6BXfG7qhjAeSPAAc0Pf6fBzA3MZrDwJOm7LPZwP79K1zT9/jh+gdac7kTUCAr3bDGK+cR+b57GcuH79T939xEL0hl/7P8c30zlHMqPvhsxe935Cu6H6w9Jvu/3KHbrv7Anf2betH9L4+tjgIuKwvz3rgkUGZtHT8ybrt+zK9X71fDHxqhnU28OiTkQd2y6D3Df/OqnrnGLLcCZwxx/X+uKpePcQ+HvPnNavqHnq/SdC98+avk1xdVd8cYvtz3u8AdwK3VdXBQ+zr4/TONRw3zWtb/i+3OBDYDNwL3A08bcsLSXam9xtaf6ZXVtWXpm40yYohcmqBeQS+jauq79P7Zn9/khcn2TnJ45I8P8nvdqutBt6SZK/uJN1b6ZUE9H6t/09JnpWeXZK8oBvPnq8rgH+W5Nz0TpzuluRZ06z3ceCFSX4pyfZJdkrvbXr7T7PuVJvoDQs8dcuCJKf1fez36JXtvN8qOMC9wLL+E4YDfBX4QZJfT++989snOTTJL8zhY/8AOJGtJ2z7rQZen+QpSXZl6zmJzfR+gJ+S5NlJdqR3cru/Az4IvDPJQQDd18M43qmkBWKB/wyoqncDv0bv1+5N9I60XsvW8dPfojfGfCPwdeC6bhlVtZbe0ev76JXfN+mdJBsmx4P0iueF9IYWbmWao8iqupPeWxzf3Jf3jczh67WqHgLeCXypGwo4kt548zVJfkjvJOA5VXXbMJ/DLPu9mV55frvb76xDTN2Y+AvpjanfBtwHfBgY+AOgqu6vqqtq+j/mfxG9sfaru+3+GPgv3cfdBJwN/Am9o/HvAf3vXX8vvX+fK5M8CHwFmO4HrCZEnNBBktrkEbgkNcoCl6RGWeCS1CgLXJIatajvA1++fHmtWLFiMXcpSc279tpr76uqvaYuX9QCX7FiBWvXrl3MXUpS85LcMd1yh1AkqVEWuCQ1ygKXpEZZ4JLUKP8a4TRWnPeZpY4gaRtz+7teMPZtegQuSY0aWOBJLurm1lvXt+xtSb6b3jyJ1yc5ebZtSJLGby5H4BfTmzx1qv9RVSu722fHG0uSNMhc/r7y1cD9i5BFkjQPo4yBvzbJjd0Qyx4zrZTkrCRrk6zdtGnTCLuTJPUbtsA/APwcvdlE7gZ+f6YVq+pDVbWqqlbttddjLuWXJA1pqAKvqnur6pGq+im9OROPGG8sSdIgQxV4kn36nv4ysG6mdSVJC2PghTxJVgPHAsuT3AX8BnBskpX0Zve+HXjNwkWUJE1nYIFX1RnTLL5wAbJIkubBS+mnsRCXvErSuHkpvSQ1ygKXpEZZ4JLUKAtckhplgUtSoyxwSWqUBS5JjbLAJalRFrgkNcoCl6RGeSn9NJyVXpp8/skLj8AlqVkjFXiS1ye5Kcm6JKuT7DSuYJKk2Q1d4En2A14HrKqqQ4HtgdPHFUySNLtRh1B2AJ6QZAdgZ2DD6JEkSXMxdIFX1XeB3wO+Q29i4+9X1ZVT13NWeklaGKMMoewBvAh4CrAvsEuSl01dz1npJWlhjDKE8lzgtqraVFUPA5cCvzieWJKkQUYp8O8ARybZOUmAE4D144klSRpklDHwa4BPAdcBX++29aEx5ZIkDZCqWrSdrVq1qtauXbto+5OkbUGSa6tq1dTlXokpSY2ywCWpURa4JDXKApekRlngktQoC1ySGmWBS1KjLHBJapQFLkmNssAlqVFOajwNJzWWE+aqBR6BS1KjLHBJatSos9Kf081If1OSc8eUSZI0B6NMqXYo8GrgCOAw4JQkB48rmCRpdqMcgT8N+EpVPVRVm4G/A355PLEkSYOMUuDrgGOSLEuyM3AycMDUlZyVXpIWxihTqq0HfgdYA3weuAHYPM16zkovSQtgpJOYVXVhVR1eVccA9wO3jieWJGmQkS7kSbJ3VW1MciDwb4GjxhNLkjTIqFdiXpJkGfAwcHZVfW8MmSRJczBSgVfVvxlXkEniZdSSWuCVmJLUKAtckhplgUtSoyxwSWqUBS5JjbLAJalRFrgkNcoCl6RGWeCS1CgLXJIa5az005jEWem9vF/SVB6BS1KjRpkT85Ak1/fdfuDExpK0eIYeQqmqbwArAZJsD3wXuGw8sSRJg4xrCOUE4FtVdceYtidJGmBcBX46sHq6F5zUWJIWxsgFnmRH4FTgk9O97qTGkrQwxnEE/nzguqq6dwzbkiTN0TgK/AxmGD6RJC2ckQo8yc7AicCl44kjSZqrUSc1fghYNqYskqR58FL6aXjZuqQWeCm9JDXKApekRlngktQoC1ySGmWBS1KjLHBJapQFLkmNssAlqVEWuCQ1ygKXpEZ5Kf00RpmV3svwJS0Wj8AlqVEDCzzJRUk2JlnXt2xlkq90s9GvTXLEwsaUJE01lyPwi4GTpiz7XeDtVbUSeGv3XJK0iAYWeFVdDdw/dTHwxO7xk4ANY84lSRpg2JOY5wJ/leT36P0Q+MWZVkxyFnAWwIEHHjjk7iRJUw17EvM/A6+vqgOA1wMXzrSis9JL0sIYtsDPZOs8mJ8EPIkpSYts2ALfADyne3w8cOt44kiS5mrgGHiS1cCxwPIkdwG/AbwaeG+SHYAf041xS5IWz8ACr6ozZnjpX485iyRpHryUfhpeDi+pBV5KL0mNssAlqVEWuCQ1ygKXpEZZ4JLUKAtckhplgUtSoyxwSWqUBS5JjbLAJalRFrgkNcoCl6RGDV3gSQ5I8rdJ1ie5Kck54wwmSZrdKH+NcDPwhqq6LsluwLVJ1lTV348pmyRpFkMfgVfV3VV1Xff4QWA9sN+4gkmSZjeWMfAkK4BnAtdM89pZSdYmWbtp06Zx7E6SxBgKPMmuwCXAuVX1g6mvOyu9JC2MkQo8yePolfcnqurSQetLksZnlHehBLgQWF9V7x5fJEnSXIxyBH408HLg+CTXd7eTx5RLkjTA0G8jrKovAhljFknSPHglpiQ1ygKXpEZZ4JLUKAtckhplgUtSoyxwSWqUBS5JjbLAJalRFrgkNcoCl6RGWeCS1CgLXJIaZYFLUqMGFniSi5JsTLKub9lhSb6c5OtJPp3kiQsbU5I01VyOwC8GTpqy7MPAeVX1r4DLgDeOOZckaYCBBV5VVwP3T1l8CHB193gN8O/GnEuSNMCwY+DrgFO7x6cBB8y0orPSS9LCGLbAXwmcneRaYDfgH2da0VnpJWlhDDWlWlXdDDwPIMk/B14wzlCSpMGGOgJPsnd3vx3wFuCD4wwlSRpsLm8jXA18GTgkyV1JXgWckeQW4GZgA/CRhY0pSZpq4BBKVZ0xw0vvHXMWSdI8eCWmJDXKApekRlngktQoC1ySGmWBS1KjLHBJapQFLkmNssAlqVEWuCQ1ygKXpEZZ4H1WnPcZVpz3maWOIUlzYoFLUqOGndR4zyRrktza3e+xsDElSVMNO6nxecBVVXUwcFX3XJK0iIad1PhFwEe7xx8FXjzeWJKkQYYdA39yVd0N0N3vPdOKTmosSQtjwU9iOqmxJC2MYQv83iT7AHT3G8cXSZI0F8MW+OXAmd3jM4G/HE8cSdJcDTup8buAE5PcCpzYPZckLaJRJjU+YcxZJEnzMLDAf5bc/q4XLHUESZozL6WXpEZZ4JLUKAtckhplgUtSoyxwSWqUBS5JjbLAJalRFrgkNcoCl6RGWeCS1Kht9lL6UWaX95J6SS3wCFySGjXsrPT/PcnNSW5MclmS3Rc0pSTpMYadlX4NcGhVPQO4BTh/zLkkSQMMNSt9VV1ZVZu7p18B9l+AbJKkWYxjDPyVwOdmetFZ6SVpYYxU4EkuADYDn5hpHWell6SFMfTbCJOcCZwCnFBVNb5IkqS5GKrAk5wE/DrwnKp6aLyRJElzMeys9O8DdgPWJLk+yQcXOKckaYphZ6W/cAGySJLmYZu9lN7L4SVt67yUXpIaZYFLUqMscElqlAUuSY2ywCWpURa4JDXKApekRlngktQoC1ySGtXMlZijTFI8X17FKakFHoFLUqMscElq1EhDKEluBx4EHgE2V9WqcYSSJA02jjHw46rqvjFsR5I0Dw6hSFKjRi3wAq5Mcm2Ss6ZbwVnpJWlhjFrgR1fV4cDzgbOTHDN1BWell6SFMVKBV9WG7n4jcBlwxDhCSZIGG7rAk+ySZLctj4HnAevGFUySNLtR3oXyZOCyJFu28ydV9fmxpJIkDTR0gVfVt4HDxphlVl7eLkmP5tsIJalRFrgkNcoCl6RGWeCS1CgLXJIalapavJ0lm4A7Fm2Hw1sOtPAHusw5fq1kbSUntJN1knMeVFWPuZR9UQu8FUnWtvCncc05fq1kbSUntJO1lZz9HEKRpEZZ4JLUKAt8eh9a6gBzZM7xayVrKzmhnayt5PwnjoFLUqM8ApekRlngktQoC7xPkpOSfCPJN5Oct9R5+iW5KMnGJOv6lu2ZZE2SW7v7PZYyY5fpgCR/m2R9kpuSnDOJWZPslOSrSW7ocr59EnNukWT7JF9LckX3fFJz3p7k60muT7K2WzapWXdP8qkkN3dfr0dNataZWOCdJNsD76c3PdzTgTOSPH1pUz3KxcBJU5adB1xVVQcDV3XPl9pm4A1V9TTgSHpT7T2dycv6E+D4qjoMWAmclORIJi/nFucA6/ueT2pOgOOqamXfe6onNet7gc9X1b+g96ex1zO5WadXVd56J3KPAv6q7/n5wPlLnWtKxhXAur7n3wD26R7vA3xjqTNOk/kvgRMnOSuwM3Ad8KxJzAnsT69MjgeumOT/e+B2YPmUZROXFXgicBvdGzkmOetsN4/At9oPuLPv+V3dskn25Kq6G6C733uJ8zxKkhXAM4FrmMCs3bDE9cBGYE1VTWRO4D3Am4Cf9i2bxJwABVyZ5NokZ3XLJjHrU4FNwEe6oakPd1NDTmLWGVngW2WaZb7HckhJdgUuAc6tqh8sdZ7pVNUjVbWS3hHuEUkOXeJIj5HkFGBjVV271Fnm6OiqOpzeUOTZSY5Z6kAz2AE4HPhAVT0T+BGTPlwyDQt8q7uAA/qe7w9sWKIsc3Vvkn0AuvuNS5wHgCSPo1fen6iqS7vFE5kVoKoeAL5A7xzDpOU8Gjg1ye3AnwLHJ/k4k5cTgKra0N1vBC4DjmAys94F3NX91gXwKXqFPolZZ2SBb/V/gYOTPCXJjsDpwOVLnGmQy4Ezu8dn0htvXlLpzXJ9IbC+qt7d99JEZU2yV5Ldu8dPAJ4L3MyE5ayq86tq/6paQe9r8m+q6mVMWE6AJLsk2W3LY+B5wDomMGtV3QPcmeSQbtEJwN8zgVlntdSD8JN0A04GbgG+BVyw1HmmZFsN3A08TO/o4VXAMnont27t7vecgJzPpjf0dCNwfXc7edKyAs8AvtblXAe8tVs+UTmnZD6WrScxJy4nvXHlG7rbTVu+hyYxa5drJbC2+xr4C2CPSc06081L6SWpUQ6hSFKjLHBJapQFLkmNssAlqVEWuCQ1ygKXpEZZ4JLUqP8Ptul/UDTWGLAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "coef = pd.Series(lassocv.coef_, index = X_train.columns).sort_values()\n",
    "imp_coef = pd.concat([coef.head(5), coef.tail(5)])\n",
    "imp_coef.plot(kind = \"barh\")\n",
    "plt.title(\"Coefficients in the Model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernel Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "독립변수 벡터  x 를 입력으로 가지는 여러개의 비선형 함수  $\\phi_j(x)$ 들을 생각해 내어 원래의 입력 변수  x 대신 $\\phi_j(x)$ 들을 입력변수로 사용한 다음과 같은 모형을 쓰면 더 좋은 예측 성능을 가질 수도 있다.\n",
    "\n",
    "$ y_i = \\sum_{j=1}^{M} w_j \\phi_j(x)  = w^T \\phi(x) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Neighbors Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 모델 원리 </b>\n",
    "\n",
    "- KNN은 새로운 데이터가 주어졌을 때 기존 데이터 가운데 가장 가까운 k개 이웃의 정보로 새로운 데이터를 예측하는 방법론입니다\n",
    "- Classification 인 경우, test point x 에 대해 가장 가까운 train set 의 k 개 이웃중 제일 많은 class로 예측을 하게 되고\n",
    "- Regression 의 경우 test point x 에 대해 가장 가까운 train set 의 k 개의 이웃의 값들의 평균으로 예측을 하게 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 모델 개요 </b>\n",
    "\n",
    "- 데이터 포인트 사이의 거리를 재는 방법과 이웃의 수 2개가 hyper parameter 이다.\n",
    "- 거리를 재는 방법은 기본적으로 여러 환경에서 잘 동작하는 유클리디안 거리 방식을 사용하므로 여기서는 다루지 않겠다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 주의점 </b>\n",
    "- k-NN 알고리즘을 사용할 땐 '거리' 가 기준이 되기때문에 데이터 값들을 모두 표준화 하여 전처리해주어야 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 장점 </b>\n",
    "- 이해하기 매우 쉬운 모델 \n",
    "- parameter을 많이 조정하지 않아도 자주 좋은 성능을 발휘합니다.\n",
    "- 더 복잡한 알고리즘을 적용해보기 전에 시도해볼 수 있는 좋은 시작점입니다.\n",
    "\n",
    "<b> 단점 </b>\n",
    "- 보통 최근접 이웃 모델은 매우 빠르게 만들 수 있지만, 훈련 세트가 매우 크면 (특성의 수나 샘플의 수가 클 경우) 예측이 느려집니다. \n",
    "- 그리고 (수백 개 이상의) 많은 특성을 가진 데이터셋에는 잘 동작하지 않으며, 특성 값 대부분이 0인 데이터셋과는 특히 잘 작동하지 않습니다.\n",
    "- k-최근접 이웃 알고리즘이 이해하긴 쉽지만, 예측이 느리고 많은 특성을 처리하는 능력이 부족해 현업에서는 잘 쓰지 않습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Hyperparameter </b>\n",
    "\n",
    "\n",
    "n_neighbors\n",
    "- 이웃의 수\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 세우기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=KNeighborsRegressor(),\n",
       "             param_grid={'n_neighbors': array([1, 2, 3, 4, 5, 6, 7, 8, 9])})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "model = KNeighborsRegressor() \n",
    "param_grid ={'n_neighbors' : np.arange(1,10)}\n",
    "model = GridSearchCV(model,param_grid,cv=5)\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 9}\n",
      "0.07674181821732715\n"
     ]
    }
   ],
   "source": [
    "print(model.best_params_) # 우리가 추정한 best parameter\n",
    "print(model.best_score_) # 우리가 지정한 scoring 에 기반한 제일 좋은 score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE : 10.361920123323124\n",
      "R squared : 0.03871893003945159\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print (\"MSE :\", metrics.mean_squared_error(y_test, y_pred))\n",
    "print(\"R squared :\", metrics.r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  DecisionTree Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> [모델 원리] </b>\n",
    "\n",
    "의사결정나무의 학습 과정은 입력 변수 영역을 두 개로 구분하는 재귀적 분기(recursive partitioning)와 너무 자세하게 구분된 영역을 통합하는 가지치기(pruning) 두 가지 과정으로 나뉩니다. \n",
    "\n",
    "재귀적 분기\n",
    "- 우선 데이터를 한 변수 기준(ex주택 크기)으로 정렬합니다. 이후 가능한 모든 분기점에 대해 엔트로피/지니계수를 구해 분기 전과 비교해 정보획득을 조사합니다. \n",
    "- 그리고 다른 변수 기준 으로 정렬한 후 위같은 과정을 반복합니다.\n",
    "- 모든 경우의 수 가운데 정보획득이 가장 큰 변수와 그 지점을 택해 첫번째 분기를 하게 됩니다. \n",
    "- 이후 또 같은 작업을 반복해 두번째, 세번째… 이렇게 분기를 full tree 가 될때까지 계속 해 나갑니다.\n",
    "\n",
    "가지치기\n",
    "- 의사결정나무 모델 학습의 또다른 축은 가지치기(pruning)입니다. 모든 terminal node의 순도가 100%인 상태를 Full tree라고 하는데요. 이렇게 Full tree를 생성한 뒤 적절한 수준에서 terminal node를 결합해주어야 합니다. 왜냐하면 분기가 너무 많아서 학습데이터에 과적합(overfitting)할 염려가 생기기 때문입니다.\n",
    "- 가지치기는 데이터를 버리는 개념이 아니고 분기를 합치는(merge) 개념으로 이해해야 합니다.\n",
    "- 가지치기의 경우 비용함수(costfunction = Err(T)+α×L(T) (Err(T) : 오분류율 , L(T) : terminal node(leaf)의 수(구조의 복잡도), α : 가중치 상수 보통 0.1~0.01 )  가 최소가 되도록 가지를 치게 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> [장점] </b>\n",
    "- 만들어진 모델을 쉽게 시각화할 수 있어서 비전문가도 이해하기 쉽습니다(비교적 작은 트리일 때). \n",
    "- 그리고 데이터의 스케일에 구애받지 않습니다. 데이터의 변수마다 트리에서는 개별적으로 처리되어 데이터를 분할하는 데 데이터 스케일의 영향을 받지 않으므로 결정 트리에서는 특성의 정규화나 표준화 같은 전처리 과정이 필요 없습니다. 특히 특성의 스케일이 서로 다르거나 이진 특성(범주형)과 연속적(연속형)인 특성이 혼합되어 있을 때도 잘 작동합니다.\n",
    "- 계산복잡성 대비 높은 예측 성능을 내는 것으로 정평이 나 있습니다. \n",
    "\n",
    "<b> [단점] </b>\n",
    "- 결정경계(decision boundary)가 데이터 축에 수직이어서 특정 데이터에만 잘 작동할 가능성이 높습니다.\n",
    "- data 의 변화에 매우 민감합니다. 데이터가 약간만 변화해도 tree 가 완전히 변화하기 떄문입니다.\n",
    "- 두 변수가 multicollinearity 관계에 있으면 decision tree will greedily choose the best one. 즉 한 변수는 아예 쳐내버립니다. 두 변수를 모두 이용하지 않는다는것입니다.\n",
    "- sample 범위 바깥의 값을 예측할 때에는 오히려 선형회귀보다 훨씬 안좋은 fitting 이 나옵니다.\n",
    "- 결정 트리의 주요 단점은 사전 가지치기를 사용함에도 불구하고 과대적합되는 경향이 있어 일반화 성능이 좋지 않다는 것입니다. 그래서 다음에 설명할 앙상블 방법을 단일 결정 트리의 대안으로 흔히 사용합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> [Hyperparameter] </b>\n",
    "\n",
    "criterion \n",
    "- 불순성의 기준을 뭐로 할지 'gini' / 'entropy' 가능\n",
    "- (defalut)= 'gini'\n",
    "\n",
    "max_depth \n",
    "- 트리의 최대 깊이. \n",
    "- 이를 이용해 사전 가지치기를 하고/ overfitting 을 해결할 수 있다.\n",
    "- (defalut) : full tree 가 될때까지 확장.\n",
    "\n",
    "min_samples_split \n",
    "- 노드에서 가지 분리할 떄 필요한 최소 sample 갯수에 제한을 준다.\n",
    "- (default) = 2 \n",
    "\n",
    "min_samples_leaf\n",
    "- leaf 에서 가져야 할 최소 sample \n",
    "- (default) = 1\n",
    "\n",
    "max_features\n",
    "- Decision tree 를 만들때 사용할 수 있는 변수의 갯수 제한\n",
    "- (default) = 총 변수 갯수 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> [Hyperparameter tuning] </b>\n",
    "-  max_depth 하나만 지정해도 과대적합을 막는 데 충분합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>[feature importance]</b>\n",
    "\n",
    "계산 원리\n",
    "\n",
    "- 노드 중요도 부터 정의해야합니다. 노드 중요도란 Information Gain을 결국 말합니다. 의사결정나무에서는 그 때 Information Gain을 최대화하는 feature를 기준으로 노드를 째게 됩니다. 어떤 노드의 노드 중요도 값이 크다는 것은 그 노드에서 특히 불순도가 크게 감소한다는 것을 의미합니다.\n",
    "- i번째 feature의 중요도 : 전체 노드의 중요도를 합한 것 대비 i번째 feature에 의해 째진 노드들의 중요도를 합한 것 입니다.\n",
    "\n",
    "의미\n",
    "\n",
    "- 이 값은 0~1 사이의 숫자로, 0은 전혀 사용되지 않았다는 뜻이고 1은 완벽하게 타깃 클래스를 예측했다는 뜻입니다. 특성 중요도의 전체 합은 1입니다.\n",
    "- Scikit-learn에서는 지니 중요도(Gini Importance)를 이용해서 각 feature의 중요도를 측정합니다\n",
    "- 그러나 어떤 특성의 feature_importance_ 값이 낮다고 해서 이 특성이 유용하지 않다는 뜻은 아닙니다. 단지 트리가 그 특성을 선택하지 않았을 뿐이며 다른 특성이 동일한 정보를 지니고 있어서일 수 있습니다.\n",
    "- 선형 모델의 계수와는 달리, 특성 중요도는 항상 양수이며 특성이 어떤 클래스를 지지하는지는 알 수 없습니다. 즉 이 변수의 영향력이 긍정적인지 부정적인지 알 수는 없습니다.\n",
    "- 하지만 feature Importance는 다소 biased하다. 특히, 랜덤 포레스트는 연속형 변수 또는 카테고리 개수가 매우 많은 변수, 즉 ‘high cardinality’ 변수들의 중요도를 더욱 부풀릴 가능성이 높다고 한다. 왜 이런 결과가 나오는지는 정확히 알 수 없으나, cardinality가 큰 변수일 수록, 노드를 쨀 게 훨씬 더 많아서 노드 중요도 값이 높게 나오는 게 아닐까 싶다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 세우기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 3}\n",
      "0.16422632977859336\n"
     ]
    }
   ],
   "source": [
    "# hyper parameter 추정하기\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "model = DecisionTreeRegressor(min_samples_split=50) \n",
    "param_grid ={'max_depth' : np.arange(1,10)}\n",
    "grid_search = GridSearchCV(model,param_grid,cv=5)\n",
    "# scoring 은 default 이므로 model 의 자체 scoring 으로 들어간다. \n",
    "grid_search.fit(X_train,y_train)\n",
    "print(grid_search.best_params_) # 우리가 추정한 best parameter\n",
    "print(grid_search.best_score_) # 우리가 지정한 scoring 에 기반한 제일 좋은 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(max_depth=3, min_samples_split=50)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 위에서 구한 최상의 parameter 로 추정하기\n",
    "model = DecisionTreeRegressor(max_depth=3,min_samples_split=50)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE : 10.167059541425555\n",
      "R squared : 0.05679625416763212\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print (\"MSE :\", metrics.mean_squared_error(y_test, y_pred))\n",
    "print(\"R squared :\", metrics.r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 변수 중요도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "feat_importances.nlargest(10).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForest Regressoion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그래디언트 부스팅 회귀 트리는 여러 개의 결정 트리를 묶어 강력한 모델을 만드는 또 다른 앙상블 방법입니다. 이름이 회귀지만 이 모델은 회귀와 분류 모두에 사용할 수 있습니다. 5 랜덤 포레스트와는 달리 그래디언트 부스팅은 이전 트리의 오차를 보완하는 방식으로 순차적으로 트리를 만듭니다. 기본적으로 그래디언트 부스팅 회귀 트리에는 무작위성이 없습니다. 대신 강력한 사전 가지치기가 사용됩니다. 그래디언트 부스팅 트리는 보통 하나에서 다섯 정도의 깊지 않은 트리를 사용하므로 메모리를 적게 사용하고 예측도 빠릅니다. 그래디언트 부스팅의 근본 아이디어는 이런 얕은 트리 같은 간단한 모델(약한 학습기weak learner라고도 합니다)을 많이 연결하는 것입니다. 각각의 트리는 데이터의 일부에 대해서만 예측을 잘 수행할 수 있어서 트리가 많이 추가될수록 성능이 좋아집니다. 6\n",
    "\n",
    "그래디언트 부스팅 트리는 머신러닝 경연 대회에서 우승을 많이 차지하였고 업계에서도 널리 사용합니다. 랜덤 포레스트보다는 매개변수 설정에 조금 더 민감하지만 잘 조정하면 더 높은 정확도를 제공해줍니다.\n",
    "\n",
    "앙상블 방식에 있는 사전 가지치기나 트리 개수 외에도 그래디언트 부스팅에서 중요한 매개변수는 이전 트리의 오차를 얼마나 강하게 보정할 것인지를 제어하는 learning_rate입니다. 학습률이 크면 트리는 보정을 강하게 하기 때문에 복잡한 모델을 만듭니다. n_estimators 값을 키우면 앙상블에 트리가 더 많이 추가되어 모델의 복잡도가 커지고 훈련 세트에서의 실수를 바로잡을 기회가 더 많아집니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "랜덤 포레스트는 텍스트 데이터 같이 매우 차원이 높고 희소한 데이터에는 잘 작동하지 않습니다. 이런 데이터에는 선형 모델이 더 적합합니다. 랜덤 포레스트는 매우 큰 데이터셋에도 잘 작동하며 훈련은 여러 CPU 코어로 간단하게 병렬화할 수 있습니다. 하지만 랜덤 포레스트는 선형 모델보다 많은 메모리를 사용하며 훈련과 예측이 느립니다. 속도와 메모리 사용에 제약이 있는 애플리케이션이라면 선형 모델이 적합할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "랜덤 포레스트에서 변수 중요도는 어떻게 될까요? 랜덤 포레스트는 의사결정나무들을 병렬적으로 합한 것이므로, 랜덤 포레스트에서 변수중요도는 결국 각 트리에서의 변수중요도를 모두 평균 낸 것에 해당합니다!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 세우기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(min_samples_split=50, oob_score=True)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model =  RandomForestRegressor(n_estimators=100,min_samples_split=50,oob_score = True)\n",
    "# scoring 은 default 이므로 model 의 자체 scoring 으로 들어간다. \n",
    "# n_estimator = 500 클수록 좋으나 내 컴퓨터가 버티질 못할듯.\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE : 9.1050983784859\n",
      "R_squared : 0.15531497954068496\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print (\"MSE :\", metrics.mean_squared_error(y_test, y_pred))\n",
    "print('R_squared :',model.score(X_test, y_test)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 변수 중요도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy86wFpkAAAACXBIWXMAAAsTAAALEwEAmpwYAAAN/0lEQVR4nO3df6xk9VnH8feni61CgRK2KAXq1or4g1/ilVRoEQo2220DoY0K8VcCEUna2BprisFIk6aJplYTU2OzBSRN6Gq07B9aa9g/jBvDD71LFlhkoRSXuixhRRBoSCxLH/+4s+Ey3L0zd86Zufd7eb+Syc6cOefO89yzfDh7Zs48qSokSe1502oXIEmajAEuSY0ywCWpUQa4JDXKAJekRh01yxfbuHFjbdq0aZYvKUnN27Vr1zNV9fbh5TMN8E2bNjE/Pz/Ll5Sk5iV5YqnlnkKRpEYZ4JLUKANckhplgEtSo2b6JuaDTz7Pphu+PvXX2fdHH5r6a0jSavMIXJIaNTLAk9ya5GCSPYuWfTbJA0l2J7kzyTumW6Ykadg4R+C3AZuHln2+qs6uqnOBfwD+sOe6JEkjjAzwqtoJPDu07IVFD48B/FJxSZqxid/ETPI54NeB54FLllnvOuA6gA3Hve5KUEnShCZ+E7Oqbqyq04DbgY8vs97WqpqrqrkNRx8/6ctJkob08SmUrwIf7eHnSJJWYKIAT3L6ooeXA3v7KUeSNK6R58CTbAMuBjYm2Q/cBGxJcgbwPeAJ4PppFilJer2RAV5VVy+x+JYp1CJJWoGZXkp/1inHM+9l7pLUCy+ll6RGGeCS1CgDXJIaZYBLUqMMcElqlAEuSY0ywCWpUQa4JDXKAJekRhngktSodTmVHpxML2n98whckho16VT6vxlMpN+dZF+S3VOtUpL0OuOcQrkN+CLwlcMLquqXD99P8gUW5mJKkmZonO8D35lk01LPJQnwS8D7e65LkjRC13Pg7wOerqpvHmmFJNclmU8y/8pLHqhLUl+6BvjVwLblVnAqvSRNx8QfI0xyFPAR4Gf6K0eSNK4uR+CXAXuran9fxUiSxjfOxwi3AXcDZyTZn+TawVNXMeL0iSRpelJVM3uxubm5mp+fn9nrSdJ6kGRXVc0NL/dKTElqlAEuSY0ywCWpUQa4JDXKAJekRhngktQoA1ySGmWAS1KjDHBJapQBLkmNWrdDjcHBxpLWN4/AJalRBrgkNWrSqfTnJLk7yYNJ/j7JcdMtU5I0bJwj8NuAzUPLbgZuqKqzgO3A7/VclyRphJEBXlU7gWeHFp8B7Bzc3wF8tOe6JEkjTHoOfA9w+eD+LwKnHWlFp9JL0nRMGuDXAB9Lsgs4FvjukVZ0Kr0kTcdEnwOvqr3ABwCS/BjgB64lacYmOgJPctLgzzcBfwB8qc+iJEmjTTqV/uokjwJ7gQPAX023TEnSMKfSS9Ia51R6SVpnDHBJapQBLkmNMsAlqVEGuCQ1ygCXpEYZ4JLUKANckhplgEtSowxwSWrUup5KD06ml7R+eQQuSY2aOMCTnJbkn5M8nOShJJ/oszBJ0vK6nEI5BPxuVd2X5FhgV5IdVfUfPdUmSVrGxEfgVfVUVd03uP8i8DBwSl+FSZKW18s58CSbgJ8G7l3iOYcaS9IUdA7wJG8FvgZ8sqpeGH7eocaSNB2dAjzJ97EQ3rdX1R39lCRJGkeXT6EEuAV4uKr+tL+SJEnj6HIEfiHwa8D7k+we3Lb0VJckaYSJP0ZYVf8KpMdaJEkrMNNL6c865XjmvbRdknrhpfSS1CgDXJIaZYBLUqMMcElqlAEuSY0ywCWpUQa4JDXKAJekRhngktQoA1ySGrXup9IvxUn1ktYDj8AlqVEjAzzJrUkOJtmzaNnnk+xN8kCS7UneNtUqJUmvM84R+G3A5qFlO4Azq+ps4FHg93uuS5I0wsgAr6qdwLNDy+6sqkODh/cAp06hNknSMvo4B34N8I0jPelUekmajq5DjW8EDgG3H2kdp9JL0nRM/DHCJL8BfBi4tKqqv5IkSeOYKMCTbAY+Dfx8Vb3Ub0mSpHGM8zHCbcDdwBlJ9ie5FvgicCywYzCN/ktTrlOSNGTkEXhVXb3E4lumUIskaQWcSi9JjfJSeklqlAEuSY0ywCWpUQa4JDXKAJekRhngktQoA1ySGmWAS1KjDHBJapQBLkmNekNOpT/M6fSSWuYRuCQ1qtMReJJ9wIvAK8ChqprroyhJ0mh9nEK5pKqe6eHnSJJWwFMoktSorgFewJ1JdiW5bqkVnEovSdPR9RTKhVV1IMlJLIxX21tVOxevUFVbga0Abzn5dIcfS1JPOh2BV9WBwZ8Hge3A+X0UJUkabeIAT3JMkmMP3wc+AOzpqzBJ0vK6nEL5QWB7ksM/56tV9U+9VCVJGmniAK+qx4FzVrKNQ40lqT9+jFCSGmWAS1KjDHBJapQBLkmNMsAlqVEGuCQ1ygCXpEYZ4JLUKANckhplgEtSo97QQ40Pc7ixpBZ5BC5JjTLAJalRXb4P/IwkuxfdXkjyyR5rkyQto8vXyT4CnAuQZAPwJAtTeSRJM9DXKZRLgW9V1RM9/TxJ0gh9BfhVwLalnnAqvSRNR+cAT/Jm4HLgb5d6vqq2VtVcVc1tOPr4ri8nSRro4wj8g8B9VfV0Dz9LkjSmPgL8ao5w+kSSND2dAjzJ0cAvAHf0U44kaVydLqWvqpeAE8dd36n0ktQfr8SUpEYZ4JLUKANckhplgEtSowxwSWqUAS5JjTLAJalRBrgkNcoAl6RGGeCS1Cin0r/B7fOrDaRmeQQuSY3q+m2En0iyJ8lDDjSWpNnqMpX+TOA3gfOBc4APJzm9r8IkScvrcgT+E8A9VfVSVR0C/gW4sp+yJEmjdAnwPcBFSU4cDHbYApw2vJJDjSVpOib+FEpVPZzkj4EdwHeA+4FDS6y3FdgK8JaTT69JX0+S9Fqd3sSsqluq6ryqugh4FvhmP2VJkkbp9DnwJCdV1cEk7wQ+AvxcP2VJkkbpeiHP15KcCLwMfKyqnuuhJknSGLoONX5fX4VIklZmppfSO5VekvrjpfSS1CgDXJIaZYBLUqMMcElqlAEuSY0ywCWpUQa4JDXKAJekRhngktQoA1ySGuVUemmG9vlVEuqRR+CS1KiuU+l/ZzCRfk+SbUm+v6/CJEnL6zKV/hTgt4G5qjoT2ABc1VdhkqTldT2FchTwA0mOAo4GDnQvSZI0jokDvKqeBP4E+DbwFPB8Vd05vJ5T6SVpOrqcQjkBuAJ4F/AO4Jgkvzq8XlVtraq5qprbcPTxk1cqSXqNLqdQLgP+s6r+u6peBu4ALuinLEnSKF0C/NvAe5IcnSTApcDD/ZQlSRqlyznwe4G/A+4DHhz8rK091SVJGqHrVPqbgJt6qkWStAJOpZekRnkpvSQ1ygCXpEYZ4JLUKANckhplgEtSowxwSWqUAS5JjTLAJalRBrgkNcqhxpI0ZdMaZu0RuCQ1ygCXpEaNDPAktyY5mGTPomWfSfJkkt2D25bplilJGjbOEfhtwOYllv9ZVZ07uP1jv2VJkkYZGeBVtRN4dga1SJJWoMs58I8neWBwiuWEI63kVHpJmo5JA/wvgXcD5wJPAV840opOpZek6ZgowKvq6ap6paq+B3wZOL/fsiRJo0wU4ElOXvTwSmDPkdaVJE3HyCsxk2wDLgY2JtnPwhDji5OcCxSwD/it6ZUoSVpKqmpmLzY3N1fz8/Mzez1JWg+S7KqqueHlXokpSY0ywCWpUQa4JDXKAJekRhngktSomX4KJcmLwCMze8Hp2wg8s9pF9GQ99QL2s9atp35m0csPV9XbhxfOdCIP8MhSH4VpVZL59dLPeuoF7GetW0/9rGYvnkKRpEYZ4JLUqFkH+NYZv960rad+1lMvYD9r3XrqZ9V6membmJKk/ngKRZIaZYBLUqN6CfAkm5M8kuSxJDcs8XyS/Png+QeSnDfutquhYz/7kjyYZHeSNfHVi2P08+NJ7k7yf0k+tZJtV0PHftbU/hmjl18Z/B17IMldSc4Zd9vV0LGfNbVvYKx+rhj0snswOvK9427bi6rqdAM2AN8CfgR4M3A/8JND62wBvgEEeA9w77jbzvrWpZ/Bc/uAjavZwwT9nAT8LPA54FMr2balftba/hmzlwuAEwb3P7gO/ttZsp+1tm9W0M9befW9xLOBvbPcP30cgZ8PPFZVj1fVd4G/Bq4YWucK4Cu14B7gbYOpPuNsO2td+lmLRvZTVQer6t+Bl1e67Sro0s9aM04vd1XVc4OH9wCnjrvtKujSz1o0Tj/fqUFiA8ewMORmrG370EeAnwL816LH+wfLxllnnG1nrUs/sLAD70yyK8l1U6tyfF1+x63un+Wspf2z0l6uZeFffpNsOwtd+oG1tW9gzH6SXJlkL/B14JqVbNtVH5fSZ4llw59NPNI642w7a136Abiwqg4kOQnYkWRvVe3stcKV6fI7bnX/LGct7Z+xe0lyCQuBd/gca9P7Zol+YG3tGxizn6raDmxPchHwWeCycbftqo8j8P3AaYsenwocGHOdcbadtS79UFWH/zwIbGfhn1KrqcvvuNX9c0RrbP+M1UuSs4GbgSuq6n9Wsu2Mdelnre0bWOHvePA/m3cn2bjSbSfWw4n+o4DHgXfx6sn6nxpa50O89k2/fxt321nfOvZzDHDsovt3AZvXej+L1v0Mr30Ts8n9s0w/a2r/jPl37Z3AY8AFk/4eGulnTe2bFfTzo7z6JuZ5wJODXJjJ/umr0S3Aoyy863rjYNn1wPWD+wH+YvD8g8Dcctuu9m3Sflh4x/n+we2hhvr5IRaOGF4A/ndw/7iG98+S/azF/TNGLzcDzwG7B7f55bZd7duk/azFfTNmP58e1LsbuBt47yz3j5fSS1KjvBJTkhplgEtSowxwSWqUAS5JjTLAJalRBrgkNcoAl6RG/T/eQgjG/yUmDQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "feat_importances.nlargest(10).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting resgressoion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 모델 원리 </b>\n",
    "\n",
    "- 부스팅은 약한 분류기를 세트로 묶어서 정확도를 예측하는 기법이다. 모래 자갈, 먼지가 섞여 있는 물질에 여러 타입의 체를 가지고 조합해서 그것을 분류하는 과정과 유사하다.\n",
    "\n",
    "- 예를 들어, 어떤 학습기 M에 대하여 Y를 예측하는 모델 Y = M(x) + error(1) 가 있다고 하자.\n",
    "- error(1) 에 대해서 설명하는 모델 G(x) 를 fitting 한다. error(1) = G(x) + error(2)\n",
    "- error(2) 에 대해서 설명하는 모델 H(x) 를 fitting 한다. error(2) = G(x) + error(3)\n",
    "- 즉 이전 모델에서 fitting 되고 남은 에러를 계속 fitting 해서 설명하는 형식으로 진행이 된다.\n",
    "- 위 모델들을 처음 model 에 적용하게 되면\n",
    "- Y = M(x) + G(x) + ............\n",
    "- 그리고 각각 분류기의 성능이 다른데, 같은비중(지금은1) 을 두면 모델의 성능이 좋지 않을것이다. 그러므로 각 모델의 성능에 비례하여 이제 각 모델 앞에 비중(weights)을 두면\n",
    "- 최종 모델 : Y = m * M(x) + g * G(x) + h * H(x) +................"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 모델 개요 </b>\n",
    "- 그래디언트 부스팅의 근본 아이디어는 이런 얕은 트리 같은 간단한 모델(약한 학습기weak learner라고도 합니다)을 많이 연결하는 것입니다. <br>\n",
    "- 이름이 회귀지만 이 모델은 회귀와 분류 모두에 사용할 수 있습니다. <br>\n",
    "- 랜덤 포레스트와는 달리 그래디언트 부스팅은 이전 트리의 오차를 보완하는 방식으로 순차적으로 트리를 만듭니다.<br>\n",
    "- 각각의 트리는 데이터의 일부에 대해서만 예측을 잘 수행할 수 있어서 트리가 많이 추가될수록 성능이 좋아집니다. <br>\n",
    "- 그래디언트 부스팅 트리는 머신러닝 경연 대회에서 우승을 많이 차지하였고 업계에서도 널리 사용합니다. 랜덤 포레스트보다는 매개변수 설정에 조금 더 민감하지만 잘 조정하면 더 높은 정확도를 제공해줍니다.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 장점 </b>\n",
    "- 그래디언트 부스팅 트리는 보통 하나에서 다섯 정도의 깊지 않은 트리를 사용하므로 메모리를 적게 사용하고 예측도 빠릅니다. <br>\n",
    "- 다른 트리 기반 모델처럼 특성의 스케일을 조정하지 않아도 되고 이진 특성이나 연속적인 특성에서도 잘 동작합니다.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 단점 </b>\n",
    "- 단점은 매개변수를 잘 조정해야 한다는 것과(매개변수 설정에 random forest 보다 민감하기때문) 훈련 시간이 길다는 것입니다.\n",
    "- 트리 기반 모델의 특성상 희소한 고차원 데이터에는 잘 작동하지 않습니다.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Hyperparameter </b>\n",
    " - n_estimators : 트리의 개수를 지정 <br>\n",
    " - learning_rate : 이전 트리의 오차를 보정하는 정도를 조절 <br>\n",
    " - max_depth : 각 모델 트리의 최대 깊이 <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Hyperparameter 조절 </b>\n",
    "- 일반적으로 기본값을 쓰는 것이 좋은 방법입니다 <br>\n",
    "- n_estimators는 클수록 좋다. 더 많은 트리를 평균하면 과대적합을 줄여 더 안정적인 모델을 만든다. 하지만 트리가 많으면 시간이 오래걸린다 <br>\n",
    "- 일반적인 관례는 가용한 시간과 메모리 한도에서 n_estimators를 맞추고 나서 적절한 learning_rate를 찾는 것.<br>\n",
    "- 각 트리의 복잡도를 낮추는 max_depth입니다. 통상 그래디언트 부스팅 모델에서는 max_depth를 매우 작게 설정하며 트리의 깊이가 5보다 깊어지지 않게 합니다<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**early stoppiny**\n",
    "- 이떄에 fitting 할때에 early stopping 을 써서, 더욱더 좋은 모델을 만들 수 있습니다.\n",
    "- early stopping 이란, 점점 더 tree 를 증가시키면서 (residual 을 학습하는것이니까요!) 학습하는 과정인데, 어느순간 과적합의 순간이 와서 val loss 가 오히려 증가할 수 있습니다.\n",
    "- 그런경우를 막기 위해 tree 를 마치 epoch 처럼 생각해 n_eastimator 를 증가시키면서 val loss 의 추이를 보고, 어느정도의 n_eastimator 를 지정해줄지 알게 된답니다!\n",
    "- fit 할떄 쓰임! bossting 모델들은 모두 가지고 있다고 생각하시면 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 세우기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(random_state=42)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE : 9.239837743558098\n",
      "R_squared : 0.1428151340023206\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print (\"MSE :\", metrics.mean_squared_error(y_test, y_pred))\n",
    "print('R_squared :',model.score(X_test, y_test)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 변수 중요도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "feat_importances.nlargest(10).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoosting Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 모델 원리 </b>\n",
    "- 처음에는 weight 1/N을 가지는(즉 뽑힐 확률이 똑같은) data로 classifier(h1)를 학습 시키고, testing을 수행한다\n",
    "\n",
    "- h1의 분류 결과로, 잘못 분류된 data가 있을 것이고, 이 data에 높은 weight(뽑힐 확률이 크게한다)를 준다\n",
    "\n",
    "- h2를 train 할 때는 h1가 틀린 데이터가 많이 포함된 데이터들로 학습 될 것이다\n",
    "\n",
    "- 그럼 h2는 h1가 틀린 데이터를 잘 분류하도록 학습 될 것이다\n",
    "\n",
    "- 즉 먼저 학습된 분류기가 잘못 분류한 것에 대한 정보를 다음 분류기가 학습할 때 사용하고, 단점을 보완하는 것이다\n",
    "\n",
    "- 이런식으로 계속 분류기가 학습된다 h1 -> h2 -> ...->hN\n",
    "\n",
    "- 각 모델이 data 를 얼마나 잘 분류했는지에 대해 a1,a2 ... 의 weight 를 준다.(잘 분류하면 큰 weight)\n",
    "\n",
    "- 예측 성능이 조금 낮은 약한 분류기들을 조합하여 최종적으로 하나의 강한 분류기를 생성한다\n",
    "\n",
    "- 최종 분류기 : f(x)= a1* h1(x)+a2* h2(x)+...+aN* hN(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 세우기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostRegressor(learning_rate=0.1, n_estimators=100, random_state=42)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "model =AdaBoostRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE : 9.204469959820555\n",
      "R_squared : 0.14609622289209434\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print (\"MSE :\", metrics.mean_squared_error(y_test, y_pred))\n",
    "print('R_squared :',model.score(X_test, y_test)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 변수 중요도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "feat_importances.nlargest(10).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # xgboost Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 세우기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xgboost란?\n",
    "\n",
    "1. 훌륭한 그라디언트 부스팅 라이브러리. 병렬 처리를 사용하기에 학습과 분류가 빠르다\n",
    "\n",
    "2. 유연성이 좋다. 평가 함수를 포함하여 다양한 커스텀 최적화 옵션을 제공한다\n",
    "\n",
    "3. 욕심쟁이(Greedy-algorithm)를 사용한 자동 가지치기가 가능하다. 따라서 과적합(Overfitting)이 잘 일어나지 않는다\n",
    "\n",
    "4. 다른 알고리즘과 연계 활용성이 좋다. xgboost 분류기 결론부 아래에 다른 알고리즘을 붙여서 앙상블 학습이 가능하다 ResNet 마지막 바로 이전 단을 Feature layer로 응용하는 것과 비슷하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xgboost는 욕심쟁이(Greedy algorithm)를 사용하여 분류기 M, G, H를 발견하고, 분산처리를 사용하여 빠른(Extreme) 속도로 적합한 비중 파라메터를 찾는 알고리즘이다. 분류기는 Regression Score를 사용하여 정확도 스코어(accuracy score)를 측정하고, 각 순서에 따라 강한 분류기부터 약한 분류기까지 랜덤 하게 생성된다. 이렇게 만들어진 분류기를 트리(tree)라고 하며, 분류기를 조합한 최종 알고리즘을 포레스트(forest)라고 한다. 여기까지가 기본적인 boosting algorithm 원리다.\n",
    "\n",
    "xgboost는 트리를 만들 때 CART(Classification And Regression Trees)라 불리는 앙상블 모델을 사용한다. 이후 트리 부스팅을 사용하여, 각 분류 기간 비중(weights)을 최적화한다. CART 모델은 일반적인 의사결정 트리(Decision Tree)와 조금 다르다. 리프 노드 하나에 대해서만 디시전 벨류를 갖는는 의사결정 트리와 달리, CART 방식은 모든 리프들이 모델의 최종 스코어에 연관되어 있다. 따라서 의사결정 트리가 분류를 제대로 했는지에 대해서만 초점을 맞추는 반면, CART는 같은 분류 결과를 갖는 모델끼리도 모델의 우위를 비교할 수 있다(스코어를 비교하면 된다). 즉, 모든 트레이닝 세트 X에 대하여 포레스트에 넣고, 결괏값으로 나오는 점수의 절대값을 더한다. 많은 데이터를 +와 -의 방향으로 보낼수록, 좋은 분류 모델이라 할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2-1. 일반 파라메터\n",
    "\n",
    "\n",
    "booster: 어떤 부스터 구조를 쓸지 결정한다. 이것은 gbtree, gblinear, dart가 있다.\n",
    "\n",
    "nthread: 몇 개의 쓰레드를 동시에 처리하도록 할지 결정한다. 디폴트는 “가능한 한 많이”.\n",
    "\n",
    "num_feature: feature 차원의 숫자를 정해야 하는 경우 옵션을 세팅한다. 디폴트는 “가능한 한 많이.”\n",
    "\n",
    "\n",
    "\n",
    "2-2. 부스팅 파라메터\n",
    "\n",
    "\n",
    "eta: learning rate다. 트리에 가지가 많을수록 과적합(overfitting) 하기 쉽다. 매 부스팅 스탭마다 weight를 주어 부스팅 과정에 과적합이 일어나지 않도록 한다\n",
    "\n",
    "gamma: 정보 획득(Information Gain)에서 -r로 표현한 바 있다. 이것이 커지면, 트리 깊이가 줄어들어 보수적인 모델이 된다. 디폴트 값은 0이다\n",
    "\n",
    "max_depth: 한 트리의 maximum depth. 숫자를 키울수록 모델의 복잡도가 커진다. 과적합 하기 쉽다. 디폴트는 6. \n",
    "\n",
    "lambda(L2 reg-form): L2 Regularization Form에 달리는 weights이다. 숫자가 클수록 보수적인 모델이 된다\n",
    "\n",
    "alpha(L1 reg-form): L1 Regularization Form weights다. 숫자가 클수록 보수적인 모델이 된다 \n",
    "\n",
    "\n",
    "\n",
    "2-3. 학습 과정 파라메터\n",
    "\n",
    "objective: 목적 함수다. reg:linear(linear-regression), binary:logistic(binary-logistic classification), count:poisson(count data poison regression) 등 다양하다\n",
    "\n",
    "eval_metric: 모델의 평가 함수를 조정하는 함수다. rmse(root mean square error), logloss(log-likelihood), map(mean average precision) 등, 해당 데이터의 특성에 맞게 평가 함수를 조정한다\n",
    "\n",
    "\n",
    "\n",
    "2-4. 커맨드 라인 파라메터\n",
    "num_rounds: boosting 라운드를 결정한다. 랜덤 하게 생성되는 모델이니만큼 이 수가 적당히 큰 게 좋다. epoch 옵션과 동일하다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. booster (부스터 모양)\n",
    "2. eval_metric (평가 함수) / objective (목적 함수)\n",
    "3. eta (러닝 레이트)\n",
    "4. L1 form (L1 레귤러라이제이션 폼이 L2보다 아웃라이어에 민감하다)\n",
    "5. L2 form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "alpha [default=0] <br>\n",
    "-L1 regularization term on weight (analogous to Lasso regression)<br>\n",
    "-Can be used in case of very high dimensionality so that the algorithm runs faster when implemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Using cached xgboost-1.1.1-py3-none-win_amd64.whl (54.4 MB)\n",
      "Requirement already satisfied: numpy in c:\\users\\goran\\anaconda3\\envs\\tensor\\lib\\site-packages (from xgboost) (1.18.5)\n",
      "Requirement already satisfied: scipy in c:\\users\\goran\\anaconda3\\envs\\tensor\\lib\\site-packages (from xgboost) (1.4.1)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-1.1.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.08, max_delta_step=0, max_depth=3,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=100, n_jobs=0, num_parallel_tree=1, random_state=0,\n",
       "             reg_alpha=1, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "model = XGBRegressor(n_estimators=100, learning_rate=0.08,max_depth=3,reg_alpha=1)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE : 9.123864862015253\n",
      "R_squared : 0.15357400246773023\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "y_pred = model.predict(X_test)\n",
    "print (\"MSE :\", metrics.mean_squared_error(y_test, y_pred))\n",
    "print('R_squared :',model.score(X_test, y_test)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 변수 중요도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "feat_importances.nlargest(10).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVR regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pros:<br>\n",
    "It works really well with a clear margin of separation<br>\n",
    "It is effective in high dimensional spaces.<br>\n",
    "It is effective in cases where the number of dimensions is greater than the number of samples.<br>\n",
    "It uses a subset of training points in the decision function (called support vectors), so it is also memory efficient.<br>\n",
    "Cons:<br>\n",
    "It doesn’t perform well when we have large data set because the required training time is higher<br>\n",
    "It also doesn’t perform very well, when the data set has more noise i.e. target classes are overlapping<br>\n",
    "SVM doesn’t directly provide probability estimates, these are calculated using an expensive five-fold cross-validation. It is included in the related SVC method of Python scikit-learn library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "parameters :\n",
    "- kernel : 커널에는 Polynomial 커널, Sigmoid 커널, 가우시안 RBF 커널 등 종류가 많은데, 그 중 가장 성능이 좋아 자주 사용되는 것이 가우시안 RBF 커널이다. 커널 기법은 주어진 데이터를 고차원 특징 공간으로 사상해주는 것이다\n",
    "- gamma : gamma는 하나의 데이터 샘플이 영향력을 행사하는 거리를 결정,결정 경계의 곡률을 조정한다고 말할 수도 있다 ,너무 낮으면 과소적합될 가능성이 크고, 너무 높으면 과대적합의 위험이 있다 <br>\n",
    "\n",
    "- C : cost(C)이다. C는 얼마나 많은 데이터 샘플이 다른 클래스에 놓이는 것을 허용하는지를 결정한다. 작을 수록 많이 허용하고, 클 수록 적게 허용한다. 다른 말로, C값을 낮게 설정하면 이상치들이 있을 가능성을 크게 잡아 일반적인 결정 경계를 찾아내고, 높게 설정하면 반대로 이상치의 존재 가능성을 작게 봐서 좀 더 세심하게 결정 경계를 찾아낸다. \"난 데이터 샘플하나도 잘못 분류할 수 없어!\"라면 C를 높여야한다. 반대로 \"몇 개는 놓쳐도 괜찮아, 이상치들이 꽤 있을 수도 있으니까\"라면 C를 낮춰야한다. 높으면 overfitting 의 문제가 있다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 세우기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SVR(),\n",
       "             param_grid={'C': [0.1, 1, 10, 100, 1000],\n",
       "                         'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
       "                         'kernel': ['rbf', 'linear', 'poly']})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "SVR = SVR()\n",
    "# gridsearch 로 최적의 parameter 를 고르자.\n",
    "param_grid = {'C': [0.1, 1, 10, 100, 1000],  \n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001], \n",
    "              'kernel': ['rbf','linear','poly']}  \n",
    "model = GridSearchCV(SVR, param_grid) \n",
    "\n",
    "# fitting the model for grid search \n",
    "model.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 100, 'gamma': 1, 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델은 어떤 경우에 최고 좋았는가?\n",
    "model.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE : 8.79871044038635\n",
      "R_squared : 0.2010870121689774\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "y_pred = svr_rbf.predict(X_test)\n",
    "print (\"MSE :\", metrics.mean_squared_error(y_test, y_pred))\n",
    "print('R_squared :',model.score(X_test, y_test)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Light gbm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. learning_rate\n",
    "\n",
    "일반적으로 0.01 ~ 0.1 정도로 맞추고 다른 파라미터를 튜닝한다. 나중에 성능을 더 높일 때 learning rate를 더 줄인다.\n",
    "\n",
    "2. num_iterations\n",
    "\n",
    "기본값이 100인데 1000정도는 해주는게 좋다. 너무 크게하면 과적합이 발생할 수 있다.\n",
    "\n",
    "같은 뜻으로 사용되는 옵션: num_iteration, n_iter, num_tree, num_trees, num_round, num_rounds, num_boost_round, n_estimators\n",
    "\n",
    "3. max_depth\n",
    "\n",
    "-1로 설정하면 제한없이 분기한다. feature가 많다면 크게 설정한다. 파라미터 설정 시 우선적으로 설정한다.\n",
    "\n",
    "4. boosting \n",
    "\n",
    "부스팅 방법: 기본값은 gbdt이며 정확도가 중요할때는 딥러닝의 드랍아웃과 같은 dart를 사용한다. 샘플링을 이용하는 goss도 있다.\n",
    "\n",
    "- boosting 🔗︎, default = gbdt, options: gbdt, rf, dart, goss\n",
    "- gbdt : traditional Gradient Boosting Decision Tree, aliases: gbrt\n",
    "- rf : Random Forest, aliases: random_forest\n",
    "- dart : Dropouts meet Multiple Additive Regression Trees\n",
    "- goss : Gradient-based One-Side Sampling\n",
    "\n",
    "5. bagging_fraction\n",
    "\n",
    "배깅을 하기위해서 데이터를 랜덤 샘플링하여 학습에 사용한다. 비율은 0 < fraction <= 1 이며 0이 되지 않게 해야한다.\n",
    "\n",
    "6. feature_fraction\n",
    "\n",
    "feature_fraction이 1보다 작다면 LGBM은 매 iteration(tree)마다 다른 feature를 랜덤하게 추출하여 학습하게된다. 만약, 0.8로 값을 설정하면 매 tree를 구성할 때, feature의 80%만 랜덤하게 선택한다. 과적합을 방지하기 위해 사용할 수 있으며 학습 속도가 향상된다.\n",
    "\n",
    "7. scale_pos_weight\n",
    "\n",
    "클래스 불균형의 데이터 셋에서 weight를 주는 방식으로 positive를 증가시킨다. 기본값은 1이며 불균형의 정도에 따라 조절한다.\n",
    "\n",
    "8. early_stopping_round\n",
    "\n",
    "Validation 셋에서 평가지표가 더 이상 향상되지 않으면 학습을 정지한다. 평가지표의 향상이 n round 이상 지속되면 학습을 정지한다.\n",
    "\n",
    "9. lambda_l1, lambda_l2\n",
    "\n",
    "정규화를 통해 과적합을 방지할 수 있지만, 정확도를 저하시킬수도 있기 때문에 일반적으로 default 값인 0으로 둔다.\n",
    "\n",
    "더 빠른 속도\n",
    "- bagging_fraction\n",
    "- max_bin은 작게\n",
    "- save_binary를 쓰면 데이터 로딩속도가 빨라짐\n",
    "- parallel learning 사용\n",
    "\n",
    "더 높은 정확도\n",
    "- max_bin을 크게\n",
    "- num_iterations 는 크게하고 learning_rate는 작게\n",
    "- num_leaves를 크게(과적합의 원인이 될 수 있음)\n",
    "- boosting 알고리즘 'dart' 사용\n",
    "\n",
    "과적합을 줄이기\n",
    "- max_bin을 작게\n",
    "- num_leaves를 작게\n",
    "- min_data_in_leaf와 min_sum_hessian_in_leaf 사용하기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l2: 9.22719\n",
      "[200]\tvalid_0's l2: 8.99339\n",
      "[300]\tvalid_0's l2: 9.03419\n",
      "Early stopping, best iteration is:\n",
      "[221]\tvalid_0's l2: 8.98184\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "train_ds = lgb.Dataset(X_train, label = y_train)\n",
    "test_ds = lgb.Dataset(X_test, label = y_test)\n",
    "params = {'learning_rate': 0.01,\n",
    "          'max_depth': 16,\n",
    "          'boosting': 'gbdt',\n",
    "          'objective': 'regression',\n",
    "          'metric': 'mse',\n",
    "          'is_training_metric': True,\n",
    "          'num_leaves': 144,\n",
    "          'feature_fraction': 0.9,\n",
    "          'bagging_fraction': 0.7,\n",
    "          'bagging_freq': 5,\n",
    "          'seed':2020}\n",
    "\n",
    "model = lgb.train(params, train_ds, 1000, test_ds, verbose_eval=100, early_stopping_rounds=100)\n",
    "\n",
    "y_pred=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.182px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
