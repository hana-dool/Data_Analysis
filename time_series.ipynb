{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "time_series.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "328.351px"
      },
      "toc_section_display": true,
      "toc_window_display": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2Pmxv2ioyCRw"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "colab_type": "code",
        "id": "b-2ShX25yNWf",
        "colab": {}
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "11Ilg92myRcw"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/structured_data/time_series\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/structured_data/time_series.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/time_series.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/tutorials/structured_data/time_series.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GU8C5qm_4vZb"
      },
      "source": [
        "This tutorial is an introduction to time series forecasting using TensorFlow. It builds a few different styles of models including Convolutional and Recurrent Neural Networks (CNNs and RNNs).\n",
        "\n",
        "This is covered in two main parts, with subsections: \n",
        "\n",
        "* Forecast for a single timestep:\n",
        "  * A single feature.\n",
        "  * All features.\n",
        "* Forecast multiple steps:\n",
        "  * Single-shot: Make the predictions all at once.\n",
        "  * Autoregressive: Make one prediction at a time and feed the output back to the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XVhK72Pu1cJL"
      },
      "source": [
        "# 세팅"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7rZnJaGTWQw0",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import datetime\n",
        "\n",
        "import IPython\n",
        "import IPython.display\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "\n",
        "mpl.rcParams['figure.figsize'] = (8, 6)\n",
        "mpl.rcParams['axes.grid'] = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eIFnfMxswVr",
        "colab_type": "text"
      },
      "source": [
        " 데이터셋 \n",
        " \n",
        " 이 데이터세트에는 대기 온도/ 대기압 / 습도 등의 14가지 값이 들어있다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xyv_i85IWInT",
        "colab": {}
      },
      "source": [
        "zip_path = tf.keras.utils.get_file(\n",
        "    origin='https://storage.googleapis.com/tensorflow/tf-keras-datasets/jena_climate_2009_2016.csv.zip',\n",
        "    fname='jena_climate_2009_2016.csv.zip',\n",
        "    extract=True)\n",
        "csv_path, _ = os.path.splitext(zip_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIXXGc6PswVu",
        "colab_type": "text"
      },
      "source": [
        "# 데이터 살펴보기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "R81Wx8WP4c3G"
      },
      "source": [
        "시간별 예측만을 다루므로 우리는 10분 간격에서 1시간으로 데이터를 서브샘플링하자."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TX6uGeeeWIkG",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(csv_path)\n",
        "# slice [start:stop:step], starting from index 5 take every 6th record.\n",
        "df = df[5::6]\n",
        "\n",
        "date_time = pd.to_datetime(df.pop('Date Time'), format='%d.%m.%Y %H:%M:%S')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ojHE-iCCWIhz",
        "colab": {}
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WRzj1inMfgcO"
      },
      "source": [
        "Here is the evolution of a few features over time. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Vg5XIc5tfNlG",
        "colab": {}
      },
      "source": [
        "plot_cols = ['T (degC)', 'p (mbar)', 'rho (g/m**3)']\n",
        "plot_features = df[plot_cols]\n",
        "plot_features.index = date_time\n",
        "_ = plot_features.plot(subplots=True)\n",
        "\n",
        "plot_features = df[plot_cols][:480]\n",
        "plot_features.index = date_time[:480]\n",
        "_ = plot_features.plot(subplots=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wXWLG0_WBhZS"
      },
      "source": [
        "# 변수 정리"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yhmZXJew6GlS"
      },
      "source": [
        "Next look at the statistics of the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "h510pgKVrrai",
        "colab": {}
      },
      "source": [
        "df.describe().transpose()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TzOTnWOoWMGK"
      },
      "source": [
        "## Wind velocity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RlG4nBOWswV4",
        "colab_type": "text"
      },
      "source": [
        "헉 windy 열이 잘못된듯 하다. -9999 가 min 값이다. 풍속이 음수일 수 는 없으므로 0 으로 넣는것이 타당해보인다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qFOq0_80vF4d",
        "colab": {}
      },
      "source": [
        "wv = df['wv (m/s)']\n",
        "bad_wv = wv == -9999.0\n",
        "wv[bad_wv] = 0.0\n",
        "\n",
        "max_wv = df['max. wv (m/s)']\n",
        "bad_max_wv = max_wv == -9999.0\n",
        "max_wv[bad_max_wv] = 0.0\n",
        "\n",
        "# The above inplace edits are reflected in the DataFrame\n",
        "df['wv (m/s)'].min()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FYyEaqiD6j4s"
      },
      "source": [
        "## Wind\n",
        "마지막 열인 wd(deg) 는 0~360 도 정보이다. 그러나 0 도와 360도는 똑같지 않나? <br>\n",
        "그리고 바람이 거의 없을떄에는 의미가 없다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YO7JGTcWQG2z",
        "colab": {}
      },
      "source": [
        "plt.hist2d(df['wd (deg)'], df['wv (m/s)'], bins=(50, 50), vmax=400)\n",
        "plt.colorbar()\n",
        "plt.xlabel('Wind Direction [deg]')\n",
        "plt.ylabel('Wind Velocity [m/s]')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yWnf5dwMU1_g"
      },
      "source": [
        "이경우에는 백터! 로 만드는게 훨씬 좋다"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxCWGHc3swV9",
        "colab_type": "text"
      },
      "source": [
        "백터로 만들게 되면, 각도가 0~360 -> X증가량/ Y증가량 으로 CONTI 하고 해석이 바로 용이한 값으로 바뀌게 된다!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6GmSTHXw6lI1",
        "colab": {}
      },
      "source": [
        "wv = df.pop('wv (m/s)')\n",
        "max_wv = df.pop('max. wv (m/s)')\n",
        "\n",
        "# Convert to radians.\n",
        "wd_rad = df.pop('wd (deg)')*np.pi / 180\n",
        "\n",
        "# Calculate the wind x and y components.\n",
        "df['Wx'] = wv*np.cos(wd_rad) # X 에 대한 방향\n",
        "df['Wy'] = wv*np.sin(wd_rad) # Y 에 대한 방향\n",
        "\n",
        "# Calculate the max wind x and y components.\n",
        "df['max Wx'] = max_wv*np.cos(wd_rad)\n",
        "df['max Wy'] = max_wv*np.sin(wd_rad)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7iI0zDoxWDyB"
      },
      "source": [
        "백터로 만들자~"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bMgCG5o2SYKD",
        "colab": {}
      },
      "source": [
        "plt.hist2d(df['Wx'], df['Wy'], bins=(50, 50), vmax=400)\n",
        "plt.colorbar()\n",
        "plt.xlabel('Wind X [m/s]')\n",
        "plt.ylabel('Wind Y [m/s]')\n",
        "ax = plt.gca()\n",
        "ax.axis('tight')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_8im1ttOWlRB"
      },
      "source": [
        "## Time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7YE21HKK40zQ"
      },
      "source": [
        "시간도 사실 매우 좋은 변수이다. 하지만 지금은 str 이므로 초로 변환하자."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LIFf-VjMfnh3",
        "colab": {}
      },
      "source": [
        "timestamp_s = date_time.map(datetime.datetime.timestamp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EC_pnM1D5Sgc"
      },
      "source": [
        "풍향과 유사하게 시간 (초)은 유용한 모델 입력이 아닙니다. 날씨 데이터이기 때문에 매일 및 매년주기가 명확합니다. 주기성을 처리 할 수있는 방법은 여러 가지가 있습니다.\n",
        "\n",
        "사용 가능한 신호로 변환하는 간단한 방법은 sin 및 cos 를 사용하여 시간을 \"시간\"및 \"시간 중\"신호를 지우도록 변환하는 것입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MBfX6CDwax73",
        "colab": {}
      },
      "source": [
        "day = 24*60*60\n",
        "year = (365.2425)*day\n",
        "\n",
        "df['Day sin'] = np.sin(timestamp_s * (2 * np.pi / day))\n",
        "df['Day cos'] = np.cos(timestamp_s * (2 * np.pi / day))\n",
        "df['Year sin'] = np.sin(timestamp_s * (2 * np.pi / year))\n",
        "df['Year cos'] = np.cos(timestamp_s * (2 * np.pi / year))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mXBbTJZfuuTC",
        "colab": {}
      },
      "source": [
        "plt.plot(np.array(df['Day sin'])[:25])\n",
        "plt.plot(np.array(df['Day cos'])[:25])\n",
        "plt.xlabel('Time [h]')\n",
        "plt.title('Time of day signal')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HiurzTGQgf_D"
      },
      "source": [
        "This gives the model access to the most important frequency features. \n",
        "\n",
        "In this case we knew ahead of time which frequencies were important. \n",
        "\n",
        "If you didn't know, you can determine which frequencies are important using an `fft`. To check our assumptions, here is the `tf.signal.rfft` of the temperature over time. Note the obvious peaks at frequencies near `1/year` and `1/day`: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EN4U1fcMiTYs",
        "colab": {}
      },
      "source": [
        "fft = tf.signal.rfft(df['T (degC)'])\n",
        "f_per_dataset = np.arange(0, len(fft))\n",
        "\n",
        "n_samples_h = len(df['T (degC)'])\n",
        "hours_per_year = 24*365.2524\n",
        "years_per_dataset = n_samples_h/(hours_per_year)\n",
        "\n",
        "f_per_year = f_per_dataset/years_per_dataset\n",
        "plt.step(f_per_year, np.abs(fft))\n",
        "plt.xscale('log')\n",
        "plt.ylim(0, 400000)\n",
        "plt.xlim([0.1, max(plt.xlim())])\n",
        "plt.xticks([1, 365.2524], labels=['1/Year', '1/day'])\n",
        "_ = plt.xlabel('Frequency (log scale)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2rbL8bSGDHy3"
      },
      "source": [
        "# 데이터 분할"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qoFJZmXBaxCc"
      },
      "source": [
        "We'll use a `(70%, 20%, 10%)` 으로 나뉜다.<br>\n",
        "이떄 주의해야할것은 랜덤으로 섞인후에 잘리는게 아니라 시간순으로 잘리는것이다.<br>\n",
        "이렇게 해야 시계열의 구조를 학습한 우리의 모델이 예측 및 테스트를 올바르게 하기 때문이다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ia-MPAHxbInX",
        "colab": {}
      },
      "source": [
        "column_indices = {name: i for i, name in enumerate(df.columns)}\n",
        "\n",
        "n = len(df)\n",
        "train_df = df[0:int(n*0.7)]\n",
        "val_df = df[int(n*0.7):int(n*0.9)]\n",
        "test_df = df[int(n*0.9):]\n",
        "\n",
        "num_features = df.shape[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-eFckdUUHWmT"
      },
      "source": [
        "# 데이터 정규화\n",
        "신경망 훈련에는 스케일링을 하는게 일반적인 방법이라고 한다. <br>\n",
        "각 피쳐의 평균을 뺴고 표준편차로 나누자. <br>\n",
        "이때 중요한것은 data leakage 현상을 막기위해 tarain 만을 사용해서 표준화시켜야 한다는 것이다<br> \n",
        "정규화는 이동평균을 이용해야한다고도 한다! 하지만 이거는 여기서 벗어난 주제이므로 정규화는 그냥 train 의 mean / std 로 표쥰화하자.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Eji6njXvHusN",
        "colab": {}
      },
      "source": [
        "train_mean = train_df.mean()\n",
        "train_std = train_df.std()\n",
        "\n",
        "train_df = (train_df - train_mean) / train_std\n",
        "val_df = (val_df - train_mean) / train_std\n",
        "test_df = (test_df - train_mean) / train_std"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "G6ufs8kk9JQw"
      },
      "source": [
        "약간 꼬리가 길어보이지만 , 그래도 -9999 처럼 에러값은 없어보인다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "T0UYEnkwm8Fe",
        "colab": {}
      },
      "source": [
        "df_std = (df - train_mean) / train_std\n",
        "df_std = df_std.melt(var_name='Column', value_name='Normalized')\n",
        "plt.figure(figsize=(12, 6))\n",
        "ax = sns.violinplot(x='Column', y='Normalized', data=df_std)\n",
        "_ = ax.set_xticklabels(df.keys(), rotation=90)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZBBmdxZ2HgfJ"
      },
      "source": [
        "# 데이터 윈도우\n",
        "이 학습서의 모델은 데이터에서 연속 된 샘플 창을 기반으로 예측 세트를 작성합니다.\n",
        "\n",
        "입력 창(window)의 주요 기능은 다음과 같습니다.\n",
        "\n",
        "- 입력 및 레이블 창의 너비 (시간 단계 수)\n",
        "- 그들 사이의 시간 오프셋.\n",
        "- 입력, 레이블 또는 둘 다로 사용되는 기능\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "F4cSEApBswWS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import Image\n",
        "Image('C:/Users/goran/Desktop/Git_hub/Data_Analasys/Pictures/Timeseries1.PNG') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rfx3jGjyziUF"
      },
      "source": [
        "# Indexes and offsets\n",
        "\n",
        "WindowGenerator 클래스를 작성하여 시작하십시오. __init__ 메소드에는 입력 및 레이블 색인에 필요한 모든 논리가 포함된다.\n",
        "\n",
        "또한 평가 및 테스트 데이터 프레임을 입력으로 사용합니다. 이것들은 나중에 윈도우의 tf.data.Dataset 로 변환된다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Kem30j8QHxyW",
        "colab": {}
      },
      "source": [
        "# 입력 / 예측 등의 데이터에 대해 INDEX들을 가지는 값들을 가지는 메서드이다.\n",
        "class WindowGenerator():\n",
        "  def __init__(self,\n",
        "               input_width, \n",
        "               label_width, \n",
        "               shift,\n",
        "               train_df=train_df,\n",
        "               val_df=val_df,\n",
        "               test_df=test_df,\n",
        "               label_columns=None):\n",
        "    # Store the raw data.\n",
        "    # 위에서 설정했던 data set 에 대해서 slef atribute 가 되게 옮긴다.\n",
        "    self.train_df = train_df\n",
        "    self.val_df = val_df\n",
        "    self.test_df = test_df\n",
        "\n",
        "    # label col 의 columns 를 맞추어준다.\n",
        "    self.label_columns = label_columns \n",
        "    # 이건 지금은 univariate 한 예측이기 떄문에 none 으로 치게 된다.\n",
        "    # label_col 이 들어가게 된다면 , \n",
        "    if label_columns is not None:\n",
        "        self.label_columns_indices = {name: i for i, name in\n",
        "                                    enumerate(label_columns)}\n",
        "    self.column_indices = {name: i for i, name in\n",
        "                           enumerate(train_df.columns)}\n",
        "\n",
        "    # Work out the window parameters.\n",
        "    self.input_width = input_width # 우리에게 주어지는 train data의 기간의 길이\n",
        "    self.label_width = label_width # 우리가 predict 하고싶은 기간의 길이\n",
        "    self.shift = shift # 우리가 predict 하게 될 때, 얼마나 train 의 마지막 기간과 떨어져있는지\n",
        "    \n",
        "    # 즉 일별데이터에서 train 은 1~15일 / 예측은 20일을 하고싶다면\n",
        "    # input_width = 15\n",
        "    # label_width = 1\n",
        "    # shift = 5 \n",
        "\n",
        "    self.total_window_size = input_width + shift\n",
        "    # 총 total window 사이즈 결정 \n",
        "\n",
        "    self.input_slice = slice(0, input_width) \n",
        "    # slice : 잘라내기 원하는 index 들을 정의하는 클래스\n",
        "    # slice 객체를 형성한다.  [0 ~ indpu_width-1] 의 리스트를 형성한다고 생각하면 쉽다.\n",
        "    # slice(0,k) 였다면 input_indices 는 [0,1,2,3....k-1]\n",
        "\n",
        "    \n",
        "    self.input_indices = np.arange(self.total_window_size)[self.input_slice]\n",
        "    # slice 의 값만큼 잘라내겠다는 의미이다.\n",
        "    # 즉 input width의 길이만큼 input_indices 를 지정해주겠다는 이야기\n",
        "    \n",
        "    # 즉 일별데이터에서 train 은 1~15일 / 예측은 20일을 하고싶다면\n",
        "    # input_width = 15\n",
        "    # input_indices = [0,1,2,.... 14]\n",
        "\n",
        "    self.label_start = self.total_window_size - self.label_width\n",
        "    # 예측하기 시작하는(즉 label_start) 지점에 대한 인덱스를 형성하고 싶다!\n",
        "    # 시작하는 값은 총 window size - 예측하고자 하는 길이\n",
        "    \n",
        "    self.labels_slice = slice(self.label_start, None)\n",
        "    # None 으로 slicing 할 경우 앞의 값까지를 없애고 slicing 하게 된다.\n",
        "    # 즉 \n",
        "    # kkk = 3\n",
        "    # np.arange(7)[slice(kkk,None)]\n",
        "    # -> array([3, 4, 5, 6])\n",
        "    \n",
        "    self.label_indices = np.arange(self.total_window_size)[self.labels_slice]\n",
        "    # 드디어 label_indies / 즉 예측에 사용되게 되는 인덱스들을 얻었다.\n",
        "    # 즉 일별데이터에서 train 은 1~15일 / 예측은 20일을 하고싶다면\n",
        "    # label_indices = [19] 가 나온다. (1일 예측이므로)\n",
        "\n",
        "\n",
        "  def __repr__(self):\n",
        "    return '\\n'.join([\n",
        "        f'Total window size: {self.total_window_size}',\n",
        "        f'Input indices: {self.input_indices}',\n",
        "        f'Label indices: {self.label_indices}',\n",
        "        f'Label column name(s): {self.label_columns}'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yVJgblsYzL1g"
      },
      "source": [
        "Here is code to create the 2 windows shown in the diagrams at the start of this section:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L97OdYgaswWX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Image('C:/Users/goran/Desktop/Git_hub/Data_Analasys/Pictures/Timeseries1.PNG') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IsM5kRkz0UwK",
        "colab": {}
      },
      "source": [
        "w1 = WindowGenerator(input_width=24, label_width=1, shift=24,\n",
        "                     label_columns=['T (degC)'])\n",
        "w1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "viwKsYeAKFUn",
        "colab": {}
      },
      "source": [
        "w2 = WindowGenerator(input_width=6, label_width=1, shift=1,\n",
        "                     label_columns=['T (degC)'])\n",
        "w2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kJaUyTWQJd-L"
      },
      "source": [
        "### 2. Split\n",
        "연속적인 입력 목록이 주어지면 split_window 메소드는 입력 창과 레이블 창으로 변환합니다.\n",
        "\n",
        "위의 예제 w2 는 다음과 같이 분할됩니다.\n",
        "\n",
        "This diagram doesn't show the `features` axis of the data, but this `split_window` function also handles the `label_columns` so it can be used for both the single output and multi-output examples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "hhuFiy3gswWc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Image('C:/Users/goran/Desktop/Git_hub/Data_Analasys/Pictures/Timeseries2.PNG') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "W4KbxfzqkXPW",
        "colab": {}
      },
      "source": [
        "# 우리는 위에서 window generator 를 적용했다고 가정하자.\n",
        "# 그러면 self 들은 input_slice 등의 메서드를 가지고 있을것이다.\n",
        "# 아직 features 를 정의하지 않아서 이게뭐지? 싶겟지만 뒤의 multivariate 에서 할테니까 걱정하지 말자\n",
        "\n",
        "def split_window(self, features):\n",
        "    # 메서드가 feature 가 추가되었다. 즉 여기에 값을 넣어주어야한다.\n",
        "    inputs = features[:, self.input_slice, :]\n",
        "    # (batch, time, features) 순서이다.\n",
        "    # time의 순서를 정해서 slicing 해야한다.\n",
        "    # features 는 데이터 이다. \n",
        "    # [X_feature 의 수:X 데이터 수:]\n",
        "    # inputs 는 어쩃든 우리가 가지고 있는 train data 의수 이다.\n",
        "    labels = features[:, self.labels_slice, :]\n",
        "    if self.label_columns is not None: # 이 값 역시 univatriat 에서는 아직 이르다.\n",
        "        labels = tf.stack(\n",
        "          [labels[:, :, self.column_indices[name]] for name in self.label_columns],\n",
        "          axis=-1)\n",
        "\n",
        "  # Slicing doesn't preserve static shape information, so set the shapes\n",
        "  # manually. This way the `tf.data.Datasets` are easier to inspect.\n",
        "    inputs.set_shape([None, self.input_width, None])\n",
        "    labels.set_shape([None, self.label_width, None])\n",
        "\n",
        "    return inputs, labels\n",
        "\n",
        "# 이제 Windowgeneratot class 에 메서드를 추가하자!\n",
        "WindowGenerator.split_window = split_window "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "G6U6VtVuM15s"
      },
      "source": [
        "Try it out:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5YSvxQfswWg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.stack([np.array([1,2,3]),\n",
        "         np.array([4,5,6])])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YeCWbq6KLmL7",
        "scrolled": false,
        "colab": {}
      },
      "source": [
        "# Stack three slices, the length of the total window:\n",
        "example_window = tf.stack([np.array(train_df[:w2.total_window_size]),\n",
        "                           np.array(train_df[100:100+w2.total_window_size]),\n",
        "                           np.array(train_df[200:200+w2.total_window_size])])\n",
        "# tf.stack 으로 행렬들을 합친다.\n",
        "# 첫번쨰 차원에 계속 적재된다. \n",
        "# 즉 w2.total_window_size 의 사이즈를 가지는 3개의 데이터셋들을 묶는다.\n",
        "# 이 경우는 batch 가 3개라고 생각하면 된다...?\n",
        "example_inputs, example_labels = w2.split_window(example_window)\n",
        "# 이제 w2 를 window 만큼 스플릿 하겠다는 의미이다.\n",
        "\n",
        "print('All shapes are: (batch, time, features)')\n",
        "print(f'Window shape: {example_window.shape}')\n",
        "# feature 가 19개인 데이터에 대해, 우선 total window 의 shape는\n",
        "# 3 , 7, 19\n",
        "print(f'Inputs shape: {example_inputs.shape}')\n",
        "# 이를 input (train) \n",
        "print(f'labels shape: {example_labels.shape}')\n",
        "# label 은"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xtMk1ffk2Mmd"
      },
      "source": [
        "Typically data in TensorFlow is packed into arrays where the outermost index is across examples (the \"batch\" dimension). The middle indices are the \"time\" or \"space\" (width, height) dimension(s). The innermost indices are the features.\n",
        "\n",
        "The code above took a batch of 2, 7-timestep windows, with 19 features at each time step. It split them into a batch of 6-timestep, 19 feature inputs, and a 1-timestep 1-feature label. The label only has one feature because the `WindowGenerator` was initialized with `label_columns=['T (degC)']`. Initially this tutorial will build models that predict single output labels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tFZukGXrJoGo"
      },
      "source": [
        "### 3. Plot\n",
        "\n",
        "Here is a plot method that allows a simple visualization of the split window:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fmgd1qkYUWT7",
        "colab": {}
      },
      "source": [
        "w2.example = example_inputs, example_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jIrYccI-Hm3B",
        "colab": {}
      },
      "source": [
        "def plot(self, model=None, plot_col='T (degC)', max_subplots=3):\n",
        "  inputs, labels = self.example\n",
        "  plt.figure(figsize=(12, 8))\n",
        "  plot_col_index = self.column_indices[plot_col]\n",
        "  max_n = min(max_subplots, len(inputs))\n",
        "  for n in range(max_n):\n",
        "    plt.subplot(3, 1, n+1)\n",
        "    plt.ylabel(f'{plot_col} [normed]')\n",
        "    plt.plot(self.input_indices, inputs[n, :, plot_col_index],\n",
        "             label='Inputs', marker='.', zorder=-10)\n",
        "\n",
        "    if self.label_columns:\n",
        "      label_col_index = self.label_columns_indices.get(plot_col, None)\n",
        "    else:\n",
        "      label_col_index = plot_col_index\n",
        "\n",
        "    if label_col_index is None:\n",
        "      continue\n",
        "\n",
        "    plt.scatter(self.label_indices, labels[n, :, label_col_index],\n",
        "                edgecolors='k', label='Labels', c='#2ca02c', s=64)\n",
        "    if model is not None:\n",
        "      predictions = model(inputs)\n",
        "      plt.scatter(self.label_indices, predictions[n, :, label_col_index],\n",
        "                  marker='X', edgecolors='k', label='Predictions',\n",
        "                  c='#ff7f0e', s=64)\n",
        "\n",
        "    if n == 0:\n",
        "      plt.legend()\n",
        "\n",
        "  plt.xlabel('Time [h]')\n",
        "\n",
        "WindowGenerator.plot = plot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HXvctEuK68vX"
      },
      "source": [
        "This plot aligns inputs, labels, and (later) predictions based on the time that the item refers to:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XjTqUnglOOni",
        "colab": {}
      },
      "source": [
        "w2.plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UqiqcPOldPG6"
      },
      "source": [
        "You can plot the other columns, but the example window `w2` configuration only has labels for the `T (degC)` column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EBRe4wnlfCH8",
        "colab": {}
      },
      "source": [
        "w2.plot(plot_col='p (mbar)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xCvD-UaUzYMw"
      },
      "source": [
        "### 4. Create `tf.data.Dataset`s"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kLO3SFR9Osdf"
      },
      "source": [
        "마지막으로이 make_dataset 메소드는 시계열 DataFrame 을 가져 tf.data.Dataset preprocessing.timeseries_dataset_from_array 함수를 사용하여 (input_window, label_window) 쌍의 tf.data.Dataset 으로 변환합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "35qoSQeRVfJg",
        "colab": {}
      },
      "source": [
        "# 시계열 데이터 프레임을 \n",
        "def make_dataset(self, data):\n",
        "    data = np.array(data, dtype=np.float32) \n",
        "    ds = tf.keras.preprocessing.timeseries_dataset_from_array(\n",
        "      data=data, # 위에서 정한 data\n",
        "      targets=None, # target 은 없다. 왜냐면 x, y 데이터는 쪼개져있기 떄문\n",
        "      sequence_length=self.total_window_size,\n",
        "      # output sequence 의 길이.\n",
        "      # total_windowz_size 를 넣어서 예측까지 포함하도록 한다.\n",
        "      sequence_stride=1, \n",
        "      # 데이터의 stride 는 1로 하고싶다.\n",
        "      shuffle=True,\n",
        "      # output sample 을 섞을지 말지.\n",
        "      batch_size=32,\n",
        "      # batch_size 는 데이터를 묶어준다.  \n",
        "    )\n",
        "\n",
        "    ds = ds.map(self.split_window) # 위 정의한것을 그냥 덮어 씌워서 출력하겠다는 뜻\n",
        "\n",
        "    return ds\n",
        "\n",
        "WindowGenerator.make_dataset = make_dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHewz-DzulK6",
        "colab_type": "text"
      },
      "source": [
        "Consider indices [0, 1, ... 99]. With sequence_length=10, sampling_rate=2, sequence_stride=3, shuffle=False, the dataset will yield batches of sequences composed of the following indices:\n",
        "\n",
        "First sequence:  [0  2  4  6  8 10 12 14 16 18]<br>\n",
        "Second sequence: [3  5  7  9 11 13 15 17 19 21]<br>\n",
        "Third sequence:  [6  8 10 12 14 16 18 20 22 24]<br>\n",
        "...<br>\n",
        "Last sequence:   [78 80 82 84 86 88 90 92 94 96]<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2uWOEBN4swWt",
        "colab_type": "text"
      },
      "source": [
        "- data: Numpy array or eager tensor containing consecutive data points (timesteps). Axis 0 is expected to be the time dimension.\n",
        "- targets: Targets corresponding to timesteps in data. It should have same length as data. targets[i] should be the target corresponding to the window that starts at index i (see example 2 below). Pass None if you don't have target data (in this case the dataset will only yield the input data).\n",
        "- sequence_length: Length of the output sequences (in number of timesteps).\n",
        "- sequence_stride: Period between successive output sequences. For stride s, output samples would start at index data[i], data[i + s], data[i + 2 * s], etc.\n",
        "- sampling_rate: Period between successive individual timesteps within sequences. For rate r, timesteps data[i], data[i + r], ... data[i + sequence_length] are used for create a sample sequence.\n",
        "- batch_size: Number of timeseries samples in each batch (except maybe the last one).\n",
        "- shuffle: Whether to shuffle output samples, or instead draw them in chronological order.\n",
        "- seed: Optional int; random seed for shuffling.\n",
        "- start_index: Optional int; data points earlier (exclusive) than start_index will not be used in the output sequences. This is useful to reserve part of the data for test or validation.\n",
        "- end_index: Optional int; data points later (exclusive) than end_index will not be used in the output sequences. This is useful to reserve part of the data for test or validation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LvsxQwJaCift"
      },
      "source": [
        "WindowGenerator 객체는 교육, 검증 및 테스트 데이터를 보유합니다. 위의 make_dataset 메소드를 사용하여 tf.data.Datasets 로 액세스하기위한 특성을 추가하십시오. 또한 쉽게 액세스하고 플로팅하기위한 표준 예제 배치를 추가하십시오.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2jZ2KkqGCfzu",
        "colab": {}
      },
      "source": [
        "# MAKE DATASET 은 train/val/test 를 모두 나오게한다..?\n",
        "@property\n",
        "def train(self):\n",
        "  return self.make_dataset(self.train_df)\n",
        "\n",
        "@property\n",
        "def val(self):\n",
        "  return self.make_dataset(self.val_df)\n",
        "\n",
        "@property\n",
        "def test(self):\n",
        "  return self.make_dataset(self.test_df)\n",
        "\n",
        "@property\n",
        "def example(self):\n",
        "  \"\"\"Get and cache an example batch of `inputs, labels` for plotting.\"\"\"\n",
        "  result = getattr(self, '_example', None)\n",
        "  if result is None:\n",
        "    # No example batch was found, so get one from the `.train` dataset\n",
        "    result = next(iter(self.train))\n",
        "    # And cache it for next time\n",
        "    self._example = result\n",
        "  return result\n",
        "\n",
        "WindowGenerator.train = train\n",
        "WindowGenerator.val = val\n",
        "WindowGenerator.test = test\n",
        "WindowGenerator.example = example"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fF_Vj6Iw3Y2w"
      },
      "source": [
        "이제 WindowGenerator 목적은 당신이에 액세스 할 수 있습니다 tf.data.Dataset 당신이 할 수있는 그렇게 쉽게 반복 처리 데이터를 통해, 객체.\n",
        "\n",
        "Dataset.element_spec 속성은 데이터 세트 요소의 구조, dtypes 및 모양을 알려줍니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "daJ0-U383YVs",
        "colab": {}
      },
      "source": [
        "# Each element is an (inputs, label) pair\n",
        "w2.train.element_spec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XKTx3_Z7ua-n"
      },
      "source": [
        "Dataset 반복하면 구체적인 배치가 생성됩니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6gtKXEgf4Iml",
        "colab": {}
      },
      "source": [
        "for example_inputs, example_labels in w2.train.take(1):\n",
        "    # take = 한번에 몇개씩 받아올지 ( 배치크기! )\n",
        "    # 위에서 w2.train 의 구조는 2개의 tensor 가 같이 있는것을 보았다.\n",
        "    # dic 형태로 input / label 을 받고있다.\n",
        "    # example_input 과 label 을 같이 w2.train 에서 같이 받아오게 된다.\n",
        "  print(f'Inputs shape (batch, time, features): {example_inputs.shape}')\n",
        "  print(f'Labels shape (batch, time, features): {example_labels.shape}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LyuGuJUgjUK3"
      },
      "source": [
        "## Single step models\n",
        "\n",
        "이러한 종류의 데이터를 기반으로 구축 할 수있는 가장 간단한 모델은 현재 조건 만 기반으로 미래에 단일 기능의 값을 1 시간 간격 (1h)으로 예측하는 모델입니다.\n",
        "\n",
        "따라서 미래의 T (degC) 값을 1h로 예측하는 모델을 구축하는 것으로 시작해 보자!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "G5QX1G1JTPCr",
        "colab": {}
      },
      "source": [
        "single_step_window = WindowGenerator(\n",
        "    input_width=1, # 우선 input_width 는 우리에게 주어진 train set 의 길이이다.\n",
        "    label_width=1, # label wifth 는 우리가 예측하고자 하는 길이이다.\n",
        "    shift=1, # 우리가 예측하는 날짜는 train 의 마지막과 얼마나 떨어쟈있는지\n",
        "    label_columns=['T (degC)']) # 어떤 label 을 뽑아낼지!\n",
        "single_step_window"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RKTm8ajVGw4N"
      },
      "source": [
        "window 개체는 교육, 유효성 검사 및 테스트 세트에서 tf.data.Datasets 를 생성하여 일괄 데이터를 쉽게 반복 할 수 있습니다.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Do4ILUaBF8oc",
        "colab": {}
      },
      "source": [
        "for example_inputs, example_labels in single_step_window.train.take(1):  \n",
        "    # take = 첫번쨰 값을 보는거\n",
        "  print(f'Inputs shape (batch, time, features): {example_inputs.shape}')\n",
        "  print(f'Labels shape (batch, time, features): {example_labels.shape}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0NnbEhbyPk4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w2.train.take(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "D1bbPiR3VAm_"
      },
      "source": [
        "### Baseline\n",
        "\n",
        "훈련 가능한 모델을 구축하기 전에 나중에보다 복잡한 모델과 비교할 수있는 성능 기준을 마련하는 것이 좋습니다.\n",
        "\n",
        "이 첫 번째 과제는 모든 기능의 현재 값을 고려하여 향후 온도 1h를 예측하는 것입니다. 현재 값에는 현재 온도가 포함됩니다.\n",
        "\n",
        "따라서 현재 온도를 예측으로 반환하고 \"변화 없음\"을 예측하는 모델로 시작하십시오. 온도가 천천히 변하기 때문에 이는 합리적인 기준입니다. 물론,이 기준선은 나중에 더 예측할 경우 효과가 떨어집니다.\n",
        "\n",
        "\n",
        "![Send the input to the output](https://github.com/hana-dool/Data_Analysis/blob/master/Pictures/Timeseries2.PNG)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9TybQaIsi3yg",
        "colab": {}
      },
      "source": [
        "class Baseline(tf.keras.Model):\n",
        "  def __init__(self, label_index=None):\n",
        "    super().__init__()\n",
        "    self.label_index = label_index\n",
        "\n",
        "  def call(self, inputs):\n",
        "    if self.label_index is None:\n",
        "      return inputs\n",
        "    result = inputs[:, :, self.label_index]\n",
        "    return result[:, :, tf.newaxis]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0vb3f948i8p8"
      },
      "source": [
        "Instantiate and evaluate this model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IS3-QKc4sX0D",
        "colab": {}
      },
      "source": [
        "baseline = Baseline(label_index=column_indices['T (degC)'])\n",
        "\n",
        "baseline.compile(loss=tf.losses.MeanSquaredError(),\n",
        "                 metrics=[tf.metrics.MeanAbsoluteError()])\n",
        "\n",
        "val_performance = {}\n",
        "performance = {}\n",
        "val_performance['Baseline'] = baseline.evaluate(single_step_window.val)\n",
        "performance['Baseline'] = baseline.evaluate(single_step_window.test, verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nhBxQcCSs7Ec"
      },
      "source": [
        "That printed some performance metrics, but those don't give you a feeling for how well the model is doing.\n",
        "\n",
        "The `WindowGenerator` has a plot method, but the plots won't be very interesting with only a single sample. So, create a wider `WindowGenerator` that generates windows 24h of consecutive inputs and labels at a time. \n",
        "\n",
        "The `wide_window` doesn't change the way the model operates. The model still makes predictions 1h into the future based on a single input time step. Here the `time` axis acts like the `batch` axis: Each prediction is made independently with no interaction between time steps."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "C8jNR5uuJ5Zp",
        "colab": {}
      },
      "source": [
        "wide_window = WindowGenerator(\n",
        "    input_width=24, label_width=24, shift=1,\n",
        "    label_columns=['T (degC)'])\n",
        "\n",
        "wide_window"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZAnj7CFZkuYv"
      },
      "source": [
        "This expanded window can be passed directly to the same `baseline` model without any code changes. This is possible because the inputs and labels have the same number of timesteps, and the baseline just forwards the input to the output:\n",
        "\n",
        "  ![One prediction 1h into the future, ever hour.](https://github.com/hana-dool/Data_Analysis/blob/master/images/last_window.png?raw=1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sGKdvdg087qs",
        "colab": {}
      },
      "source": [
        "print('Input shape:', single_step_window.example[0].shape)\n",
        "print('Output shape:', baseline(single_step_window.example[0]).shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SKqQHX1K0JW-"
      },
      "source": [
        "Plotting the baseline model's predictions you can see that it is simply the labels, shifted right by 1h."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jQyAPVLgWTOZ",
        "colab": {}
      },
      "source": [
        "wide_window.plot(baseline)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "e93TLUhfAVg2"
      },
      "source": [
        "위의 세 가지 예에서 단일 단계 모델은 24 시간 동안 실행됩니다. 이것은 약간의 설명이 필요합니다.\n",
        "\n",
        "- 파란색 \"입력\"라인은 각 시간 단계에서의 입력 온도를 나타냅니다. 모델은 모든 피쳐를 수신하며이 플롯에는 온도 만 표시됩니다.\n",
        "- 녹색 \"라벨\"도트는 목표 예측 값을 나타냅니다. 이 점들은 입력 시간이 아니라 예측 시간에 표시됩니다. 그렇기 때문에 라벨 범위가 입력에 대해 1 단계 씩 이동합니다.\n",
        "- 주황색 \"예측\"교차는 각 출력 시간 단계에 대한 모델의 예측입니다. 모델이 완벽하게 예측하는 경우 예측은 \"라벨\"에 직접 도달합니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "E4aOJScj52Yu"
      },
      "source": [
        "### Linear model\n",
        "\n",
        "The simplest **trainable** model you can apply to this task is to insert linear transformation between the input and output. In this case the output from a time step only depends on that step:\n",
        "\n",
        "![A single step prediction](https://github.com/hana-dool/Data_Analysis/blob/master/images/narrow_window.png?raw=1)\n",
        "\n",
        "A `layers.Dense` with no `activation` set is a linear model. The layer only transforms the last axis of the data from `(batch, time, inputs)` to `(batch, time, units)`, it is applied independently to every item across the `batch` and `time` axes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6341OXuQ5xA9",
        "colab": {}
      },
      "source": [
        "linear = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(units=1)\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KwaOM8RucUSn",
        "colab": {}
      },
      "source": [
        "print('Input shape:', single_step_window.example[0].shape)\n",
        "print('Output shape:', linear(single_step_window.example[0]).shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OMZTYIj3bYLg"
      },
      "source": [
        "This tutorial trains many models, so package the training procedure into a function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CbCL6VIrk-Gt",
        "colab": {}
      },
      "source": [
        "MAX_EPOCHS = 20\n",
        "\n",
        "def compile_and_fit(model, window, patience=2):\n",
        "  early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
        "                                                    patience=patience,\n",
        "                                                    mode='min')\n",
        "\n",
        "  model.compile(loss=tf.losses.MeanSquaredError(),\n",
        "                optimizer=tf.optimizers.Adam(),\n",
        "                metrics=[tf.metrics.MeanAbsoluteError()])\n",
        "\n",
        "  history = model.fit(window.train, epochs=MAX_EPOCHS,\n",
        "                      validation_data=window.val,\n",
        "                      callbacks=[early_stopping])\n",
        "  return history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OobVjM-schwj"
      },
      "source": [
        "Train the model and evaluate its performance:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9agbz2qB9bLS",
        "colab": {}
      },
      "source": [
        "history = compile_and_fit(linear, single_step_window)\n",
        "\n",
        "val_performance['Linear'] = linear.evaluate(single_step_window.val)\n",
        "performance['Linear'] = linear.evaluate(single_step_window.test, verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7U9XukYh8beN"
      },
      "source": [
        "Like the `baseline` model, the linear model can be called on batches of wide windows. Used this way the model makes a set of independent predictions on consecuitive time steps. The `time` axis acts like another `batch` axis. There are no interactions between the precictions at each time step.\n",
        "\n",
        "![A single step prediction](https://github.com/hana-dool/Data_Analysis/blob/master/images/wide_window.png?raw=1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "K9UVM5Sw9KQN",
        "colab": {}
      },
      "source": [
        "print('Input shape:', wide_window.example[0].shape)\n",
        "print('Output shape:', baseline(wide_window.example[0]).shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "X-CGj85oKaOG"
      },
      "source": [
        "Here is the plot of its example predictions on the `wide_widow`, note how in many cases the prediction is clearly better than just returning the input temperature, but in a few cases it's worse:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bCC8VVo-OvwV",
        "colab": {}
      },
      "source": [
        "wide_window.plot(linear)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Is51vU8EMl6c"
      },
      "source": [
        "One advantage to linear models is that they're relatively simple to  interpret.\n",
        "You can pull out the layer's weights, and see the weight assigned to each input:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "d4uCTbsmK8VI",
        "colab": {}
      },
      "source": [
        "plt.bar(x = range(len(train_df.columns)),\n",
        "        height=linear.layers[0].kernel[:,0].numpy())\n",
        "axis = plt.gca()\n",
        "axis.set_xticks(range(len(train_df.columns)))\n",
        "_ = axis.set_xticklabels(train_df.columns, rotation=90)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ylng7215boIY"
      },
      "source": [
        "Sometimes the model doesn't even place the most weight on the input `T (degC)`. This is one of the risks of random initialization. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "W18e6da1cNbw"
      },
      "source": [
        "### Dense\n",
        "\n",
        "Before applying models that actually operate on multiple time-steps, it's worth checking the performance of deeper, more powerful, single input step models.\n",
        "\n",
        "Here's a model similar to the `linear` model, except it stacks several a few `Dense` layers between the input and the output: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Z86WkYp7cNAD",
        "colab": {}
      },
      "source": [
        "dense = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
        "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
        "    tf.keras.layers.Dense(units=1)\n",
        "])\n",
        "\n",
        "history = compile_and_fit(dense, single_step_window)\n",
        "\n",
        "val_performance['Dense'] = dense.evaluate(single_step_window.val)\n",
        "performance['Dense'] = dense.evaluate(single_step_window.test, verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "j5dv_whJdswH"
      },
      "source": [
        "### Multi-step dense\n",
        "\n",
        "A single-time-step model has no context for the current values of its inputs. It can't see how the input features are changing over time. To address this issue the model needs access to multiple time steps when making predictions:\n",
        "\n",
        "![Three time steps are used for each prediction.](https://github.com/hana-dool/Data_Analysis/blob/master/images/conv_window.png?raw=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Zac-ti8agbJ7"
      },
      "source": [
        "The `baseline`, `linear` and `dense` models handled each time step independently. Here the model will take multiple time steps as input to produce a single output.\n",
        "\n",
        "Create a `WindowGenerator` that will produce batches of the 3h of inputs and, 1h of labels:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gtN4BwZ37niR"
      },
      "source": [
        "Note that the `Window`'s `shift` parameter is relative to the end of the two windows.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lBh0j5djUKY2",
        "colab": {}
      },
      "source": [
        "CONV_WIDTH = 3\n",
        "conv_window = WindowGenerator(\n",
        "    input_width=CONV_WIDTH,\n",
        "    label_width=1,\n",
        "    shift=1,\n",
        "    label_columns=['T (degC)'])\n",
        "\n",
        "conv_window"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dCQ5gvs68Xkd",
        "colab": {}
      },
      "source": [
        "conv_window.plot()\n",
        "plt.title(\"Given 3h as input, predict 1h into the future.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "We0HdMxKeqB_"
      },
      "source": [
        "You could train a `dense` model on a multiple-input-step window by adding a `layers.Flatten` as the first layer of the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oNQnUOkOnC1G",
        "colab": {}
      },
      "source": [
        "multi_step_dense = tf.keras.Sequential([\n",
        "    # Shape: (time, features) => (time*features)\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(units=32, activation='relu'),\n",
        "    tf.keras.layers.Dense(units=32, activation='relu'),\n",
        "    tf.keras.layers.Dense(units=1),\n",
        "    # Add back the time dimension.\n",
        "    # Shape: (outputs) => (1, outputs)\n",
        "    tf.keras.layers.Reshape([1, -1]),\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cayD74luo4Vq",
        "colab": {}
      },
      "source": [
        "print('Input shape:', conv_window.example[0].shape)\n",
        "print('Output shape:', multi_step_dense(conv_window.example[0]).shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fu91yEbRo9-J",
        "colab": {}
      },
      "source": [
        "history = compile_and_fit(multi_step_dense, conv_window)\n",
        "\n",
        "IPython.display.clear_output()\n",
        "val_performance['Multi step dense'] = multi_step_dense.evaluate(conv_window.val)\n",
        "performance['Multi step dense'] = multi_step_dense.evaluate(conv_window.test, verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tnqdXYT6pkEh",
        "colab": {}
      },
      "source": [
        "conv_window.plot(multi_step_dense)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gWfrsP8mq8lV"
      },
      "source": [
        "The main down-side of this approach is that the resulting model can only be executed on input wndows of exactly this shape. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "j-q6tz5Yq8Jk",
        "colab": {}
      },
      "source": [
        "print('Input shape:', wide_window.example[0].shape)\n",
        "try:\n",
        "  print('Output shape:', multi_step_dense(wide_window.example[0]).shape)\n",
        "except Exception as e:\n",
        "  print(f'\\n{type(e).__name__}:{e}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bvvajm3ip_8V"
      },
      "source": [
        "The convolutional models in the next section fix this problem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CrpU6gwSJome"
      },
      "source": [
        "### Convolution neural network\n",
        " \n",
        "A convolution layer (`layers.Conv1D`) also takes multiple time steps as input to each prediction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cdLBwoaHmsWb"
      },
      "source": [
        "Below is the **same** model as `multi_step_dense`, re-written with a convolution. \n",
        "\n",
        "Note the changes:\n",
        "* The `layers.Flatten` and the first `layers.Dense` are replaced by a `layers.Conv1D`.\n",
        "* The `layers.Reshape` is no longer necessary since the convolution keeps the time axis in its output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5azaMBj4ac9t",
        "colab": {}
      },
      "source": [
        "conv_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv1D(filters=32,\n",
        "                           kernel_size=(CONV_WIDTH,),\n",
        "                           activation='relu'),\n",
        "    tf.keras.layers.Dense(units=32, activation='relu'),\n",
        "    tf.keras.layers.Dense(units=1),\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ftaH6B5ECRiK"
      },
      "source": [
        "Run it on an example batch to see that the model produces outputs with the expected shape:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5YNgt1-e98lH",
        "colab": {}
      },
      "source": [
        "print(\"Conv model on `conv_window`\")\n",
        "print('Input shape:', conv_window.example[0].shape)\n",
        "print('Output shape:', conv_model(conv_window.example[0]).shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5m4kC-jGCY3x"
      },
      "source": [
        "Train and evaluate it on the ` conv_window` and it should give performance similar to the `multi_step_dense` model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QDVWdm4paUW7",
        "colab": {}
      },
      "source": [
        "history = compile_and_fit(conv_model, conv_window)\n",
        "\n",
        "IPython.display.clear_output()\n",
        "val_performance['Conv'] = conv_model.evaluate(conv_window.val)\n",
        "performance['Conv'] = conv_model.evaluate(conv_window.test, verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sYRipDeXs0Kr"
      },
      "source": [
        "The difference between this `conv_model` and the `multi_step_dense` model is that the `conv_model` can be run on inputs on inputs of any length. The convolutional layer is applied to a sliding window of inputs:\n",
        "\n",
        "![Executing a convolutional model on a sequence](https://github.com/hana-dool/Data_Analysis/blob/master/images/wide_conv_window.png?raw=1)\n",
        "\n",
        "If you run it on wider input, it produces wider output:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hoqccxx9r5jF",
        "colab": {}
      },
      "source": [
        "print(\"Wide window\")\n",
        "print('Input shape:', wide_window.example[0].shape)\n",
        "print('Labels shape:', wide_window.example[1].shape)\n",
        "print('Output shape:', conv_model(wide_window.example[0]).shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "h_WGxtLIHhRF"
      },
      "source": [
        "Note that the output is shorter than the input. To make training or plotting work, you need the labels, and prediction to have the same length. So build a `WindowGenerator` to produce wide windows with a few extra input time steps so the label and prediction lengths match: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_VPvJ_VwTc0f",
        "colab": {}
      },
      "source": [
        "LABEL_WIDTH = 24\n",
        "INPUT_WIDTH = LABEL_WIDTH + (CONV_WIDTH - 1)\n",
        "wide_conv_window = WindowGenerator(\n",
        "    input_width=INPUT_WIDTH,\n",
        "    label_width=LABEL_WIDTH,\n",
        "    shift=1,\n",
        "    label_columns=['T (degC)'])\n",
        "\n",
        "wide_conv_window"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gtqlWYXeKXej",
        "colab": {}
      },
      "source": [
        "print(\"Wide conv window\")\n",
        "print('Input shape:', wide_conv_window.example[0].shape)\n",
        "print('Labels shape:', wide_conv_window.example[1].shape)\n",
        "print('Output shape:', conv_model(wide_conv_window.example[0]).shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yzxbbS56cSBV"
      },
      "source": [
        "Now you can plot the model's predictions on a wider window. Note the 3 input time steps before the first prediction. Every prediction here is based on the 3 preceding timesteps:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gR7VyL45UuEe",
        "colab": {}
      },
      "source": [
        "wide_conv_window.plot(conv_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "H4crpOcoMlSe"
      },
      "source": [
        "### Recurrent neural network\n",
        "\n",
        "A Recurrent Neural Network (RNN) is a type of neural network well-suited to time series data. RNNs process a time series step-by-step, maintaining an internal state from time-step to time-step.\n",
        "\n",
        "For more details, read the [text generation tutorial](https://www.tensorflow.org/tutorials/text/text_generation) or the [RNN guide](https://www.tensorflow.org/guide/keras/rnn). \n",
        "\n",
        "In this tutorial, you will use an RNN layer called Long Short Term Memory ([LSTM](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/LSTM))."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vfQbHSMb1ATa"
      },
      "source": [
        "An important constructor argument for all keras RNN layers is the `return_sequences` argument. This setting can configure the layer in one of two ways.\n",
        "\n",
        "1. If `False`, the default, the layer only returns the output of the final timestep, giving the model time to warm up its internal state before making a single prediction: \n",
        "\n",
        "![An lstm warming up and making a single prediction](https://github.com/hana-dool/Data_Analysis/blob/master/images/lstm_1_window.png?raw=1)\n",
        "\n",
        "2. If `True` the layer returns an output for each input. This is useful for:\n",
        "  * Stacking RNN layers. \n",
        "  * Training a model on multiple timesteps simultaneously.\n",
        "\n",
        "![An lstm making a prediction after every timestep](https://github.com/hana-dool/Data_Analysis/blob/master/images/lstm_many_window.png?raw=1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DXKLCJy8nWNU",
        "colab": {}
      },
      "source": [
        "lstm_model = tf.keras.models.Sequential([\n",
        "    # Shape [batch, time, features] => [batch, time, lstm_units]\n",
        "    tf.keras.layers.LSTM(32, return_sequences=True),\n",
        "    # Shape => [batch, time, features]\n",
        "    tf.keras.layers.Dense(units=1)\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "F124B00KZcLC"
      },
      "source": [
        "With `return_sequences=True` the model can be trained on 24h of data at a time.\n",
        "\n",
        "Note: This will give a pessimistic view of the model's performance. On the first timestep the model has no access to previous steps, and so can't do any better than the simple `linear` and `dense` models shown earlier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eZEROCQVYV6q",
        "colab": {}
      },
      "source": [
        "print('Input shape:', wide_window.example[0].shape)\n",
        "print('Output shape:', lstm_model(wide_window.example[0]).shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uvdWRl1e9WJl",
        "colab": {}
      },
      "source": [
        "history = compile_and_fit(lstm_model, wide_window)\n",
        "\n",
        "IPython.display.clear_output()\n",
        "val_performance['LSTM'] = lstm_model.evaluate(wide_window.val)\n",
        "performance['LSTM'] = lstm_model.evaluate(wide_window.test, verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NwAOWCVgB26e",
        "colab": {}
      },
      "source": [
        "wide_window.plot(lstm_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pYglOCKehi8F"
      },
      "source": [
        "### Performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2pCk0_rwhi8H"
      },
      "source": [
        "With this dataset typically each of the models does slightly better than the one before it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JjEkt488hi8I",
        "colab": {}
      },
      "source": [
        "x = np.arange(len(performance))\n",
        "width = 0.3\n",
        "metric_name = 'mean_absolute_error'\n",
        "metric_index = lstm_model.metrics_names.index('mean_absolute_error')\n",
        "val_mae = [v[metric_index] for v in val_performance.values()]\n",
        "test_mae = [v[metric_index] for v in performance.values()]\n",
        "\n",
        "plt.ylabel('mean_absolute_error [T (degC), normalized]')\n",
        "plt.bar(x - 0.17, val_mae, width, label='Validation')\n",
        "plt.bar(x + 0.17, test_mae, width, label='Test')\n",
        "plt.xticks(ticks=x, labels=performance.keys(),\n",
        "           rotation=45)\n",
        "_ = plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cBMCpsdphi8L",
        "colab": {}
      },
      "source": [
        "for name, value in performance.items():\n",
        "  print(f'{name:12s}: {value[1]:0.4f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "b5rUJ_2YMWzG"
      },
      "source": [
        "### Multi-output models\n",
        "\n",
        "The models so far all predicted a single output feature, `T (degC)`, for a single time step.\n",
        "\n",
        "All of these models can be converted to predict multiple features just by changing the number of units in the output layer and adjusting the training windows to include all features in the `labels`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9Gk0Z91xjOwv",
        "colab": {}
      },
      "source": [
        "single_step_window = WindowGenerator(\n",
        "    # `WindowGenerator` returns all features as labels if you \n",
        "    # don't set the `label_columns` argument.\n",
        "    input_width=1, label_width=1, shift=1)\n",
        "\n",
        "wide_window = WindowGenerator(\n",
        "    input_width=24, label_width=24, shift=1)\n",
        "\n",
        "for example_inputs, example_labels in wide_window.train.take(1):\n",
        "  print(f'Inputs shape (batch, time, features): {example_inputs.shape}')\n",
        "  print(f'Labels shape (batch, time, features): {example_labels.shape}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XmcjHfDskX1N"
      },
      "source": [
        "Note above that the `features` axis of the labels now has the same depth as the inputs, instead of 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9k7S5IHNhSNF"
      },
      "source": [
        "#### Baseline\n",
        "\n",
        "The same baseline model can be used here, but this time repeating all features instead of selecting a specific `label_index`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sqqB9W-pjr5i",
        "colab": {}
      },
      "source": [
        "baseline = Baseline()\n",
        "baseline.compile(loss=tf.losses.MeanSquaredError(),\n",
        "                 metrics=[tf.metrics.MeanAbsoluteError()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ltQdgaqQjQWu",
        "colab": {}
      },
      "source": [
        "val_performance = {}\n",
        "performance = {}\n",
        "val_performance['Baseline'] = baseline.evaluate(wide_window.val)\n",
        "performance['Baseline'] = baseline.evaluate(wide_window.test, verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dfbCrf5q3P6n"
      },
      "source": [
        "#### Dense"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NdpzH1dYjdIN",
        "colab": {}
      },
      "source": [
        "dense = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
        "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
        "    tf.keras.layers.Dense(units=num_features)\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6uHuU9Cd3PTo",
        "colab": {}
      },
      "source": [
        "history = compile_and_fit(dense, single_step_window)\n",
        "\n",
        "IPython.display.clear_output()\n",
        "val_performance['Dense'] = dense.evaluate(single_step_window.val)\n",
        "performance['Dense'] = dense.evaluate(single_step_window.test, verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dsc9pur_mHsx"
      },
      "source": [
        "#### RNN\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4QbGLMyomXaz",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "wide_window = WindowGenerator(\n",
        "    input_width=24, label_width=24, shift=1)\n",
        "\n",
        "lstm_model = tf.keras.models.Sequential([\n",
        "    # Shape [batch, time, features] => [batch, time, lstm_units]\n",
        "    tf.keras.layers.LSTM(32, return_sequences=True),\n",
        "    # Shape => [batch, time, features]\n",
        "    tf.keras.layers.Dense(units=num_features)\n",
        "])\n",
        "\n",
        "history = compile_and_fit(lstm_model, wide_window)\n",
        "\n",
        "IPython.display.clear_output()\n",
        "val_performance['LSTM'] = lstm_model.evaluate( wide_window.val)\n",
        "performance['LSTM'] = lstm_model.evaluate( wide_window.test, verbose=0)\n",
        "\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UwhY2f_Nn0_K"
      },
      "source": [
        "<a id=\"residual\"></a>\n",
        "\n",
        "#### Advanced: Residual connections\n",
        "\n",
        "The `Baseline` model from earlier took advantage of the fact that the sequence doesn't change drastically from time step to time step. Every model trained in this tutorial so far was randomly initialized, and then had to learn that the output is a a small change from the previous time step.\n",
        "\n",
        "While you can get around this issue with careful initialization, it's  simpler to build this into the model structure.\n",
        "\n",
        "It's common in time series analysis to build models that instead of predicting the next value, predict the how the value will change in the next timestep.\n",
        "Similarly, \"Residual networks\" or \"ResNets\" in deep learning refer to architectures where each layer adds to the model's accumulating result.\n",
        "\n",
        "That is how you take advantage of the knowledge that the change should be small.\n",
        "\n",
        "![A model with a residual connection](https://github.com/hana-dool/Data_Analysis/blob/master/images/residual.png?raw=1)\n",
        "\n",
        "Essentially this initializes the model to match the `Baseline`. For this task it helps models converge faster, with slightly better performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yP58A_ORx0kM"
      },
      "source": [
        "This approach can be used in conjunction with any model discussed in this tutorial. \n",
        "\n",
        "Here it is being applied to the LSTM model, note the use of the `tf.initializers.zeros` to ensure that the initial predicted changes are small, and don't overpower the residual connection. There are no symmetry-breaking concerns for the gradients here, since the `zeros` are only used on the last layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7YlfnDQC22TQ",
        "colab": {}
      },
      "source": [
        "class ResidualWrapper(tf.keras.Model):\n",
        "  def __init__(self, model):\n",
        "    super().__init__()\n",
        "    self.model = model\n",
        "\n",
        "  def call(self, inputs, *args, **kwargs):\n",
        "    delta = self.model(inputs, *args, **kwargs)\n",
        "\n",
        "    # The prediction for each timestep is the input\n",
        "    # from the previous time step plus the delta\n",
        "    # calculated by the model.\n",
        "    return inputs + delta"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NNeH02pspc9B",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "residual_lstm = ResidualWrapper(\n",
        "    tf.keras.Sequential([\n",
        "    tf.keras.layers.LSTM(32, return_sequences=True),\n",
        "    tf.keras.layers.Dense(\n",
        "        num_features,\n",
        "        # The predicted deltas should start small\n",
        "        # So initialize the output layer with zeros\n",
        "        kernel_initializer=tf.initializers.zeros)\n",
        "]))\n",
        "\n",
        "history = compile_and_fit(residual_lstm, wide_window)\n",
        "\n",
        "IPython.display.clear_output()\n",
        "val_performance['Residual LSTM'] = residual_lstm.evaluate(wide_window.val)\n",
        "performance['Residual LSTM'] = residual_lstm.evaluate(wide_window.test, verbose=0)\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "I42Er9Du6co1"
      },
      "source": [
        "#### Performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LZxR38P_6pUi"
      },
      "source": [
        "Here is the overall performance for these multi-output models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6XgTK9tnr7rc",
        "colab": {}
      },
      "source": [
        "x = np.arange(len(performance))\n",
        "width = 0.3\n",
        "\n",
        "metric_name = 'mean_absolute_error'\n",
        "metric_index = lstm_model.metrics_names.index('mean_absolute_error')\n",
        "val_mae = [v[metric_index] for v in val_performance.values()]\n",
        "test_mae = [v[metric_index] for v in performance.values()]\n",
        "\n",
        "plt.bar(x - 0.17, val_mae, width, label='Validation')\n",
        "plt.bar(x + 0.17, test_mae, width, label='Test')\n",
        "plt.xticks(ticks=x, labels=performance.keys(),\n",
        "           rotation=45)\n",
        "plt.ylabel('MAE (average over all outputs)')\n",
        "_ = plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "URz3ajCc6kBj",
        "colab": {}
      },
      "source": [
        "for name, value in performance.items():\n",
        "  print(f'{name:15s}: {value[1]:0.4f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_Vt2MJhNxwPU"
      },
      "source": [
        "The above performances are averaged across all model outputs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eYokb7Om2YbK"
      },
      "source": [
        "## Multi-step models\n",
        "\n",
        "Both the single-output and multiple-output models in the previous sections made **single time step predictions**, 1h into the future.\n",
        "\n",
        "This section looks at how to expand these models to make **multiple time step predictions**.\n",
        "\n",
        "In a multi-step prediction, the model needs to learn to predict a range of future values. Thus, unlike a single step model, where only a single future point is predicted, a multi-step model predicts a sequence of the future values.\n",
        "\n",
        "There are two rough approaches to this:\n",
        "\n",
        "1. Single shot predictions where the entire time series is predicted at once.\n",
        "2. Autoregressive predictions where the model only makes single step predictions and its output is fed back as its input.\n",
        "\n",
        "In this section all the models will predict **all the features across all output time steps**.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WFsDAwVt4_rq"
      },
      "source": [
        "For the multi-step model, the training data again consists of hourly samples. However, here, the models will learn to predict 24h of the future, given 24h of the past.\n",
        "\n",
        "Here is a `Window` object that generates these slices from the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1cFYtsz6XiGw",
        "colab": {}
      },
      "source": [
        "OUT_STEPS = 24\n",
        "multi_window = WindowGenerator(input_width=24,\n",
        "                               label_width=OUT_STEPS,\n",
        "                               shift=OUT_STEPS)\n",
        "\n",
        "multi_window.plot()\n",
        "multi_window"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5lg8SInh9Jzd"
      },
      "source": [
        "### Baselines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "axwpoWYOApJL"
      },
      "source": [
        "A simple baseline for this task is to repeat the last input time step for the required number of output timesteps:\n",
        "\n",
        "![Repeat the last input, for each output step](https://github.com/hana-dool/Data_Analysis/blob/master/images/multistep_last.png?raw=1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_5iaHSaJ9Rxv",
        "colab": {}
      },
      "source": [
        "class MultiStepLastBaseline(tf.keras.Model):\n",
        "  def call(self, inputs):\n",
        "    return tf.tile(inputs[:, -1:, :], [1, OUT_STEPS, 1])\n",
        "\n",
        "last_baseline = MultiStepLastBaseline()\n",
        "last_baseline.compile(loss=tf.losses.MeanSquaredError(),\n",
        "                      metrics=[tf.metrics.MeanAbsoluteError()])\n",
        "\n",
        "multi_val_performance = {}\n",
        "multi_performance = {}\n",
        "\n",
        "multi_val_performance['Last'] = last_baseline.evaluate(multi_window.val)\n",
        "multi_performance['Last'] = last_baseline.evaluate(multi_window.val, verbose=0)\n",
        "multi_window.plot(last_baseline)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AvHZ93ObAfMA"
      },
      "source": [
        "Since this task is to predict 24h given 24h another simple approach is to repeat the previous day, assuming tomorrow will be similar:\n",
        "\n",
        "![Repeat the previous day](https://github.com/hana-dool/Data_Analysis/blob/master/images/multistep_repeat.png?raw=1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "L8Y1uMhGwIRs",
        "colab": {}
      },
      "source": [
        "class RepeatBaseline(tf.keras.Model):\n",
        "  def call(self, inputs):\n",
        "    return inputs\n",
        "\n",
        "repeat_baseline = RepeatBaseline()\n",
        "repeat_baseline.compile(loss=tf.losses.MeanSquaredError(),\n",
        "                        metrics=[tf.metrics.MeanAbsoluteError()])\n",
        "\n",
        "multi_val_performance['Repeat'] = repeat_baseline.evaluate(multi_window.val)\n",
        "multi_performance['Repeat'] = repeat_baseline.evaluate(multi_window.test, verbose=0)\n",
        "multi_window.plot(repeat_baseline)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tbndS-ct9C2Q"
      },
      "source": [
        "### Single-shot models\n",
        "\n",
        "One high level approach to this problem is use a \"single-shot\" model, where the model makes the entire sequence prediction in a single step.\n",
        "\n",
        "This can be implemented efficiently as a `layers.Dense` with `OUT_STEPS*features` output units. The model just needs to reshape that output to the required `(OUTPUT_STEPS, features)`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NCKS4m1VKrDQ"
      },
      "source": [
        "#### Linear\n",
        "\n",
        "A simple linear model based on the last input time step does better than either baseline, but is underpowered. The model needs to predict `OUTPUT_STEPS` time steps, from a single input time step with a linear projection. It can only capture a low-dimensional slice of the behavior, likely based mainly on the time of day and time of year.\n",
        "\n",
        "![Predct all timesteps from the last time-step](https://github.com/hana-dool/Data_Analysis/blob/master/images/multistep_dense.png?raw=1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kfRz_WVhIQcd",
        "colab": {}
      },
      "source": [
        "multi_linear_model = tf.keras.Sequential([\n",
        "    # Take the last time-step.\n",
        "    # Shape [batch, time, features] => [batch, 1, features]\n",
        "    tf.keras.layers.Lambda(lambda x: x[:, -1:, :]),\n",
        "    # Shape => [batch, 1, out_steps*features]\n",
        "    tf.keras.layers.Dense(OUT_STEPS*num_features,\n",
        "                          kernel_initializer=tf.initializers.zeros),\n",
        "    # Shape => [batch, out_steps, features]\n",
        "    tf.keras.layers.Reshape([OUT_STEPS, num_features])\n",
        "])\n",
        "\n",
        "history = compile_and_fit(multi_linear_model, multi_window)\n",
        "\n",
        "IPython.display.clear_output()\n",
        "multi_val_performance['Linear'] = multi_linear_model.evaluate(multi_window.val)\n",
        "multi_performance['Linear'] = multi_linear_model.evaluate(multi_window.test, verbose=0)\n",
        "multi_window.plot(multi_linear_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zi2TMHk2IRrh"
      },
      "source": [
        "#### Dense\n",
        "\n",
        "Adding a `layers.Dense` between the input and output gives the linear model more power, but is still only based on a single input timestep."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jezm-BKaGj91",
        "colab": {}
      },
      "source": [
        "multi_dense_model = tf.keras.Sequential([\n",
        "    # Take the last time step.\n",
        "    # Shape [batch, time, features] => [batch, 1, features]\n",
        "    tf.keras.layers.Lambda(lambda x: x[:, -1:, :]),\n",
        "    # Shape => [batch, 1, dense_units]\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    # Shape => [batch, out_steps*features]\n",
        "    tf.keras.layers.Dense(OUT_STEPS*num_features,\n",
        "                          kernel_initializer=tf.initializers.zeros),\n",
        "    # Shape => [batch, out_steps, features]\n",
        "    tf.keras.layers.Reshape([OUT_STEPS, num_features])\n",
        "])\n",
        "\n",
        "history = compile_and_fit(multi_dense_model, multi_window)\n",
        "\n",
        "IPython.display.clear_output()\n",
        "multi_val_performance['Dense'] = multi_dense_model.evaluate(multi_window.val)\n",
        "multi_performance['Dense'] = multi_dense_model.evaluate(multi_window.test, verbose=0)\n",
        "multi_window.plot(multi_dense_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "icsBAjCzMaMl"
      },
      "source": [
        "#### CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "34lCZrWYNBwd"
      },
      "source": [
        "A convolutional model makes predictions based on a fixed-width history, which may lead to better performance than the dense model since it can see how things are changing over time:\n",
        "\n",
        "![A convolutional model sees how things change over time](https://github.com/hana-dool/Data_Analysis/blob/master/images/multistep_conv.png?raw=1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0xJoIP6PMWMI",
        "colab": {}
      },
      "source": [
        "CONV_WIDTH = 3\n",
        "multi_conv_model = tf.keras.Sequential([\n",
        "    # Shape [batch, time, features] => [batch, CONV_WIDTH, features]\n",
        "    tf.keras.layers.Lambda(lambda x: x[:, -CONV_WIDTH:, :]),\n",
        "    # Shape => [batch, 1, conv_units]\n",
        "    tf.keras.layers.Conv1D(256, activation='relu', kernel_size=(CONV_WIDTH)),\n",
        "    # Shape => [batch, 1,  out_steps*features]\n",
        "    tf.keras.layers.Dense(OUT_STEPS*num_features,\n",
        "                          kernel_initializer=tf.initializers.zeros),\n",
        "    # Shape => [batch, out_steps, features]\n",
        "    tf.keras.layers.Reshape([OUT_STEPS, num_features])\n",
        "])\n",
        "\n",
        "history = compile_and_fit(multi_conv_model, multi_window)\n",
        "\n",
        "IPython.display.clear_output()\n",
        "\n",
        "multi_val_performance['Conv'] = multi_conv_model.evaluate(multi_window.val)\n",
        "multi_performance['Conv'] = multi_conv_model.evaluate(multi_window.test, verbose=0)\n",
        "multi_window.plot(multi_conv_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "weBjeZAFJOP4"
      },
      "source": [
        "#### RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8022xOKxOO92"
      },
      "source": [
        "A recurrent model can learn to use a long history of inputs, if it's relevant to the predictions the model is making. Here the model will accumulate internal state for 24h, before making a single prediction for the next 24h.\n",
        "\n",
        "In this single-shot format, the LSTM only needs to produce an output at the last time step, so set `return_sequences=False`.\n",
        "\n",
        "![The lstm accumulates state over the input window, and makes a single prediction for the next 24h](https://github.com/hana-dool/Data_Analysis/blob/master/images/multistep_lstm.png?raw=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Bf1ks6RTzF64",
        "colab": {}
      },
      "source": [
        "multi_lstm_model = tf.keras.Sequential([\n",
        "    # Shape [batch, time, features] => [batch, lstm_units]\n",
        "    # Adding more `lstm_units` just overfits more quickly.\n",
        "    tf.keras.layers.LSTM(32, return_sequences=False),\n",
        "    # Shape => [batch, out_steps*features]\n",
        "    tf.keras.layers.Dense(OUT_STEPS*num_features,\n",
        "                          kernel_initializer=tf.initializers.zeros),\n",
        "    # Shape => [batch, out_steps, features]\n",
        "    tf.keras.layers.Reshape([OUT_STEPS, num_features])\n",
        "])\n",
        "\n",
        "history = compile_and_fit(multi_lstm_model, multi_window)\n",
        "\n",
        "IPython.display.clear_output()\n",
        "\n",
        "multi_val_performance['LSTM'] = multi_lstm_model.evaluate(multi_window.val)\n",
        "multi_performance['LSTM'] = multi_lstm_model.evaluate(multi_window.train, verbose=0)\n",
        "multi_window.plot(multi_lstm_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "d5n-1cDW12Vo"
      },
      "source": [
        "### Advanced: Autoregressive model\n",
        "\n",
        "The above models all predict the entire output sequence as a in a single step.\n",
        "\n",
        "In some cases it may be helpful for the model to decompose this prediction into individual time steps. Then each model's output can be fed back into itself at each step and predictions can be made conditioned on the previous one, like in the classic [Generating Sequences With Recurrent Neural Networks](https://arxiv.org/abs/1308.0850).\n",
        "\n",
        "One clear advantage to this style of model is that it can be set up to produce output with a varying length.\n",
        "\n",
        "You could take any of single single-step multi-output models trained in the first half of this tutorial and run  in an autoregressive feedback loop, but here we'll focus on building a model that's been explicitly trained to do that.\n",
        "\n",
        "![Feedback a model's output to its input](https://github.com/hana-dool/Data_Analysis/blob/master/images/multistep_autoregressive.png?raw=1)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PKRreBbULRXY"
      },
      "source": [
        "#### RNN\n",
        "\n",
        "This tutorial only builds an autoregressive RNN model, but this pattern could be applied to any model that was designed to output a single timestep.\n",
        "\n",
        "The model will have the same basic form as the single-step `LSTM` models: An `LSTM` followed by a `layers.Dense` that converts the `LSTM` outputs to model predictions.\n",
        "\n",
        "A `layers.LSTM` is a `layers.LSTMCell` wrapped in the higher level `layers.RNN` that manages the state and sequence results for you (See [Keras RNNs](https://www.tensorflow.org/guide/keras/rnn) for details).\n",
        "\n",
        "In this case the model has to manually manage the inputs for each step so it uses `layers.LSTMCell` directly for the lower level, single time step interface."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "s5tz3Nu0R5JG",
        "colab": {}
      },
      "source": [
        "class FeedBack(tf.keras.Model):\n",
        "  def __init__(self, units, out_steps):\n",
        "    super().__init__()\n",
        "    self.out_steps = out_steps\n",
        "    self.units = units\n",
        "    self.lstm_cell = tf.keras.layers.LSTMCell(units)\n",
        "    # Also wrap the LSTMCell in an RNN to simplify the `warmup` method.\n",
        "    self.lstm_rnn = tf.keras.layers.RNN(self.lstm_cell, return_state=True)\n",
        "    self.dense = tf.keras.layers.Dense(num_features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2OXVM9G1U7xR",
        "colab": {}
      },
      "source": [
        "feedback_model = FeedBack(units=32, out_steps=OUT_STEPS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ph5uFSfTUNho"
      },
      "source": [
        "The first method this model needs is a `warmup` method to initialize is its internal state based on the inputs. Once trained this state will capture the relevant parts of the input history. This is equivalent to the single-step `LSTM` model from earlier:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vM2K_LLdRjDZ",
        "colab": {}
      },
      "source": [
        "def warmup(self, inputs):\n",
        "  # inputs.shape => (batch, time, features)\n",
        "  # x.shape => (batch, lstm_units)\n",
        "  x, *state = self.lstm_rnn(inputs)\n",
        "\n",
        "  # predictions.shape => (batch, features)\n",
        "  prediction = self.dense(x)\n",
        "  return prediction, state\n",
        "\n",
        "FeedBack.warmup = warmup"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6JkaSYaZ9eB7"
      },
      "source": [
        "This method returns a single time-step prediction, and the internal state of the LSTM:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "w9Fz6NTKXXwU",
        "colab": {}
      },
      "source": [
        "prediction, state = feedback_model.warmup(multi_window.example[0])\n",
        "prediction.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "S_ZdvPjdX3y3"
      },
      "source": [
        "With the `RNN`'s state, and an initial prediction you can now continue iterating the model feeding the predictions at each step back as the input.\n",
        "\n",
        "The simplest approach to collecting the output predictions is to use a python list, and `tf.stack` after the loop."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yotTad3nZXQU"
      },
      "source": [
        "Note: Stacking a python list like this only works with eager-execution, using `Model.compile(..., run_eagerly=True)` for training, or with a fixed length output. For a dynamic output length you would need to use a `tf.TensorArray` instead of a python list, and `tf.range` instead of the python `range`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "g1GRDu3mZtr9",
        "colab": {}
      },
      "source": [
        "def call(self, inputs, training=None):\n",
        "  # Use a TensorArray to capture dynamically unrolled outputs.\n",
        "  predictions = []\n",
        "  # Initialize the lstm state\n",
        "  prediction, state = self.warmup(inputs)\n",
        "\n",
        "  # Insert the first prediction\n",
        "  predictions.append(prediction)\n",
        "\n",
        "  # Run the rest of the prediction steps\n",
        "  for n in range(1, self.out_steps):\n",
        "    # Use the last prediction as input.\n",
        "    x = prediction\n",
        "    # Execute one lstm step.\n",
        "    x, state = self.lstm_cell(x, states=state,\n",
        "                              training=training)\n",
        "    # Convert the lstm output to a prediction.\n",
        "    prediction = self.dense(x)\n",
        "    # Add the prediction to the output\n",
        "    predictions.append(prediction)\n",
        "\n",
        "  # predictions.shape => (time, batch, features)\n",
        "  predictions = tf.stack(predictions)\n",
        "  # predictions.shape => (batch, time, features)\n",
        "  predictions = tf.transpose(predictions, [1, 0, 2])\n",
        "  return predictions\n",
        "\n",
        "FeedBack.call = call"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ubop-YWp15XW"
      },
      "source": [
        "Test run this model on the example inputs:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Xja83zEYaM2D",
        "colab": {}
      },
      "source": [
        "print('Output shape (batch, time, features): ', feedback_model(multi_window.example[0]).shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qMs0rYB8be9M"
      },
      "source": [
        "Now train the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VBRVG2hnNyrO",
        "colab": {}
      },
      "source": [
        "history = compile_and_fit(feedback_model, multi_window)\n",
        "\n",
        "IPython.display.clear_output()\n",
        "\n",
        "multi_val_performance['AR LSTM'] = feedback_model.evaluate(multi_window.val)\n",
        "multi_performance['AR LSTM'] = feedback_model.evaluate(multi_window.test, verbose=0)\n",
        "multi_window.plot(feedback_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hGjcJsAQJUkI"
      },
      "source": [
        "### Performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sODAwr2ndtDB"
      },
      "source": [
        "There are clearly diminishing returns as a function of model complexity on this problem."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WZwWBA8S6B3L",
        "colab": {}
      },
      "source": [
        "x = np.arange(len(multi_performance))\n",
        "width = 0.3\n",
        "\n",
        "\n",
        "metric_name = 'mean_absolute_error'\n",
        "metric_index = lstm_model.metrics_names.index('mean_absolute_error')\n",
        "val_mae = [v[metric_index] for v in multi_val_performance.values()]\n",
        "test_mae = [v[metric_index] for v in multi_performance.values()]\n",
        "\n",
        "plt.bar(x - 0.17, val_mae, width, label='Validation')\n",
        "plt.bar(x + 0.17, test_mae, width, label='Test')\n",
        "plt.xticks(ticks=x, labels=multi_performance.keys(),\n",
        "           rotation=45)\n",
        "plt.ylabel(f'MAE (average over all times and outputs)')\n",
        "_ = plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Zq3hUsedCEmJ"
      },
      "source": [
        "The metrics for the multi-output models in the first half of this tutorial show the performance averaged across all output features. These performances similar but also averaged across output timesteps. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jKq3eAIvH4Db",
        "colab": {}
      },
      "source": [
        "for name, value in multi_performance.items():\n",
        "  print(f'{name:8s}: {value[1]:0.4f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MpBFwfnaHP23"
      },
      "source": [
        "The gains achieved going from a dense model to convolutional and recurrent models are only a few percent (if any), and the autoregressive model performed clearly worse. So these more complex approaches may not be worth while on **this** problem, but there was no way to know without trying, and these models could be helpful for **your** problem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pOzaIRYBhqwg"
      },
      "source": [
        "## Next steps\n",
        "\n",
        "This tutorial was a quick introduction to time series forecasting using TensorFlow.\n",
        "\n",
        "* For further understanding, see:\n",
        "  * Chapter 15 of [Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow](https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/), 2nd Edition \n",
        "  * Chapter 6 of [Deep Learning with Python](https://www.manning.com/books/deep-learning-with-python).\n",
        "  * Lesson 8 of [Udacity's intro to TensorFlow for deep learning](https://www.udacity.com/course/intro-to-tensorflow-for-deep-learning--ud187), and the [exercise notebooks](https://github.com/tensorflow/examples/tree/master/courses/udacity_intro_to_tensorflow_for_deep_learning) \n",
        "* Also remember that you can implement any [classical time series model](https://otexts.com/fpp2/index.html) in TensorFlow, this tutorial just focuses on TensdorFlow's built-in functionality."
      ]
    }
  ]
}